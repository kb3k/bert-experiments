{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a080b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code : https://github.com/jaimezorno/Deep-Learning-for-NLP-Creating-a-Chatbot/blob/master/Deep%20Learning%20for%20NLP-%20Creating%20a%20chatbot.ipynb\n",
    "# post : https://towardsdatascience.com/deep-learning-for-nlp-creating-a-chatbot-with-keras-da5ca051e051\n",
    "# ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "322114a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add,  dot, concatenate, LSTM\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c274913",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = pd.read_csv(\"data/wine reviews.csv\")\n",
    "wine_reviews_447_1 = pd.read_csv(\"data/447_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18d27e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc): \n",
    "    \"\"\"\n",
    "    Sometimes you need bleach,\n",
    "    sometimes CLR.\n",
    "    sometimes you wash the walls\n",
    "    sometimes the floors.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    tokens = doc.split()\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [tkn.lower() for tkn in tokens if not tkn in stop_words]\n",
    "    \n",
    "    tokens = [tkn for tkn in tokens if tkn != '']\n",
    "    \n",
    "    return tokens # tokens is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9fdeea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2890, 32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dd69c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>flavors</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13ClKCGV-KLJ3akN68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gallo</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:11Z</td>\n",
       "      <td>2018-01-10T18:06:28Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0 in x 1.0 in x 1.0 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>This a fantastic white wine for any occasion!</td>\n",
       "      <td>My Favorite White Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bjh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>4.9213E+11</td>\n",
       "      <td>1.0 lbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV13CsvW-jtxr-f38AQO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fresh Craft Co.</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:42Z</td>\n",
       "      <td>2018-01-10T05:38:33Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...</td>\n",
       "      <td>4.25 in x 4.25 in x 5.25 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
       "      <td>Yum!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>83120003441</td>\n",
       "      <td>2.45 lbs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id asins            brand  \\\n",
       "0  AV13ClKCGV-KLJ3akN68   NaN            Gallo   \n",
       "1  AV13CsvW-jtxr-f38AQO   NaN  Fresh Craft Co.   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:11Z   \n",
       "1  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:42Z   \n",
       "\n",
       "            dateUpdated                                       descriptions  \\\n",
       "0  2018-01-10T18:06:28Z                                                NaN   \n",
       "1  2018-01-10T05:38:33Z  [{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...   \n",
       "\n",
       "                     dimension  ean flavors  ...  \\\n",
       "0     1.0 in x 1.0 in x 1.0 in  NaN     NaN  ...   \n",
       "1  4.25 in x 4.25 in x 5.25 in  NaN     NaN  ...   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "1  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "\n",
       "                                       reviews.text           reviews.title  \\\n",
       "0     This a fantastic white wine for any occasion!  My Favorite White Wine   \n",
       "1  Tart, not sweet...very refreshing and delicious!                   Yum!!   \n",
       "\n",
       "  reviews.userCity reviews.userProvince reviews.username sizes  \\\n",
       "0              NaN                  NaN              Bjh   NaN   \n",
       "1              NaN                  NaN             Wino   NaN   \n",
       "\n",
       "                                          sourceURLs          upc    weight  \n",
       "0  http://redsky.target.com/v1/plp/search?kwr=y&c...   4.9213E+11   1.0 lbs  \n",
       "1  http://redsky.target.com/v1/plp/search?kwr=y&c...  83120003441  2.45 lbs  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35b11bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1231, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews_447_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7db44f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>flavors</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.sourceURLs</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV00t6hpvKc47QAVgBMG</td>\n",
       "      <td>B00GFYMHRE</td>\n",
       "      <td>DUPLIN</td>\n",
       "      <td>Food,Beverages,Beer, Wine &amp; Spirits,Wine,Red</td>\n",
       "      <td>2017-07-12T02:53:57Z</td>\n",
       "      <td>2018-01-08T08:00:32Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-07-20T18:11:00.000Z\",\"2017...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82504912348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.walmart.com/reviews/product/101824387</td>\n",
       "      <td>A sweet smooth taste in every drop.</td>\n",
       "      <td>I love the sweet smooth muscadine taste.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lexie</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Duplin-Carolina-Red...</td>\n",
       "      <td>82504912348</td>\n",
       "      <td>2 pounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV00tABdGV-KLJ3ac19r</td>\n",
       "      <td>B06ZZCZD5W</td>\n",
       "      <td>WOODFORD RESERVE</td>\n",
       "      <td>Food,Beverages,Beer, Wine &amp; Spirits,Cocktail M...</td>\n",
       "      <td>2017-07-12T02:49:58Z</td>\n",
       "      <td>2017-09-06T04:49:34Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-08-23T10:57:30.792Z\"],\"sou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>http://www.ebay.com/itm/Woodford-Reserve-Spice...</td>\n",
       "      <td>This is a terrific product. Just a few drops i...</td>\n",
       "      <td>Delicious!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tulipkoda46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.walmart.com/ip/Woodford-Reserve-Sp...</td>\n",
       "      <td>8.55783E+11</td>\n",
       "      <td>4.8 ounces</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id       asins             brand  \\\n",
       "0  AV00t6hpvKc47QAVgBMG  B00GFYMHRE            DUPLIN   \n",
       "1  AV00tABdGV-KLJ3ac19r  B06ZZCZD5W  WOODFORD RESERVE   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0       Food,Beverages,Beer, Wine & Spirits,Wine,Red  2017-07-12T02:53:57Z   \n",
       "1  Food,Beverages,Beer, Wine & Spirits,Cocktail M...  2017-07-12T02:49:58Z   \n",
       "\n",
       "            dateUpdated                                       descriptions  \\\n",
       "0  2018-01-08T08:00:32Z  [{\"dateSeen\":[\"2017-07-20T18:11:00.000Z\",\"2017...   \n",
       "1  2017-09-06T04:49:34Z  [{\"dateSeen\":[\"2017-08-23T10:57:30.792Z\"],\"sou...   \n",
       "\n",
       "  dimension          ean flavors  ...  \\\n",
       "0       NaN  82504912348     NaN  ...   \n",
       "1       NaN          NaN     NaN  ...   \n",
       "\n",
       "                                  reviews.sourceURLs  \\\n",
       "0  https://www.walmart.com/reviews/product/101824387   \n",
       "1  http://www.ebay.com/itm/Woodford-Reserve-Spice...   \n",
       "\n",
       "                                        reviews.text  \\\n",
       "0                A sweet smooth taste in every drop.   \n",
       "1  This is a terrific product. Just a few drops i...   \n",
       "\n",
       "                              reviews.title reviews.userCity  \\\n",
       "0  I love the sweet smooth muscadine taste.              NaN   \n",
       "1                                Delicious!              NaN   \n",
       "\n",
       "  reviews.userProvince reviews.username sizes  \\\n",
       "0                  NaN            Lexie   NaN   \n",
       "1                  NaN      tulipkoda46   NaN   \n",
       "\n",
       "                                          sourceURLs          upc      weight  \n",
       "0  https://www.walmart.com/ip/Duplin-Carolina-Red...  82504912348    2 pounds  \n",
       "1  https://www.walmart.com/ip/Woodford-Reserve-Sp...  8.55783E+11  4.8 ounces  \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_reviews_447_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4953758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([wine_reviews, wine_reviews_447_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f23cf7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>flavors</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>quantities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13ClKCGV-KLJ3akN68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gallo</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:11Z</td>\n",
       "      <td>2018-01-10T18:06:28Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0 in x 1.0 in x 1.0 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>My Favorite White Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bjh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>4.9213E+11</td>\n",
       "      <td>1.0 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV13CsvW-jtxr-f38AQO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fresh Craft Co.</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:42Z</td>\n",
       "      <td>2018-01-10T05:38:33Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...</td>\n",
       "      <td>4.25 in x 4.25 in x 5.25 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yum!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>83120003441</td>\n",
       "      <td>2.45 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV13CVI_glJLPUi8O7Po</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000 Stories</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:05Z</td>\n",
       "      <td>2018-01-10T05:38:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3 in x 3.3 in x 11.79 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>A New Favorite!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bama Mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>82896001453</td>\n",
       "      <td>3.09 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV13CVI_glJLPUi8O7Po</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000 Stories</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:05Z</td>\n",
       "      <td>2018-01-10T05:38:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3 in x 3.3 in x 11.79 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Av Dub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>82896001453</td>\n",
       "      <td>3.09 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV13CYL4-jtxr-f37_-t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wine Cube153</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:18Z</td>\n",
       "      <td>2018-01-10T18:06:29Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...</td>\n",
       "      <td>1.0 in x 1.0 in x 1.0 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
       "      <td>Overland Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chelseamay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>85200600465</td>\n",
       "      <td>1.0 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id asins            brand  \\\n",
       "0  AV13ClKCGV-KLJ3akN68   NaN            Gallo   \n",
       "1  AV13CsvW-jtxr-f38AQO   NaN  Fresh Craft Co.   \n",
       "2  AV13CVI_glJLPUi8O7Po   NaN     1000 Stories   \n",
       "3  AV13CVI_glJLPUi8O7Po   NaN     1000 Stories   \n",
       "4  AV13CYL4-jtxr-f37_-t   NaN     Wine Cube153   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:11Z   \n",
       "1  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:42Z   \n",
       "2  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:05Z   \n",
       "3  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:05Z   \n",
       "4  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:18Z   \n",
       "\n",
       "            dateUpdated                                       descriptions  \\\n",
       "0  2018-01-10T18:06:28Z                                                NaN   \n",
       "1  2018-01-10T05:38:33Z  [{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...   \n",
       "2  2018-01-10T05:38:31Z                                                NaN   \n",
       "3  2018-01-10T05:38:31Z                                                NaN   \n",
       "4  2018-01-10T18:06:29Z  [{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...   \n",
       "\n",
       "                     dimension  ean flavors  ...  \\\n",
       "0     1.0 in x 1.0 in x 1.0 in  NaN     NaN  ...   \n",
       "1  4.25 in x 4.25 in x 5.25 in  NaN     NaN  ...   \n",
       "2   3.3 in x 3.3 in x 11.79 in  NaN     NaN  ...   \n",
       "3   3.3 in x 3.3 in x 11.79 in  NaN     NaN  ...   \n",
       "4     1.0 in x 1.0 in x 1.0 in  NaN     NaN  ...   \n",
       "\n",
       "                          reviews.title reviews.userCity reviews.userProvince  \\\n",
       "0                My Favorite White Wine              NaN                  NaN   \n",
       "1                                 Yum!!              NaN                  NaN   \n",
       "2                       A New Favorite!              NaN                  NaN   \n",
       "3  Bold, Flavorful, Aromatic, Delicious              NaN                  NaN   \n",
       "4  Yum! Plus, Environmentally Friendly!    Overland Park                  NaN   \n",
       "\n",
       "  reviews.username sizes                                         sourceURLs  \\\n",
       "0              Bjh   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "1             Wino   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "2         Bama Mom   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "3           Av Dub   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "4       Chelseamay   NaN  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "\n",
       "           upc    weight primaryCategories  quantities  \n",
       "0   4.9213E+11   1.0 lbs               NaN         NaN  \n",
       "1  83120003441  2.45 lbs               NaN         NaN  \n",
       "2  82896001453  3.09 lbs               NaN         NaN  \n",
       "3  82896001453  3.09 lbs               NaN         NaN  \n",
       "4  85200600465   1.0 lbs               NaN         NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b0777d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Food Beverages & Tobacco',\n",
       "       'Food Beverages & Tobacco,Food Beverages & Tobacco',\n",
       "       'Home & Garden,Food Beverages & Tobacco,Home & Garden',\n",
       "       'Food Beverages & Tobacco,Health & Beauty',\n",
       "       'Food Beverages & Tobacco,Home & Garden',\n",
       "       'Home & Garden,Food Beverages & Tobacco'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.primaryCategories.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a2d4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asins</th>\n",
       "      <th>brand</th>\n",
       "      <th>categories</th>\n",
       "      <th>dateAdded</th>\n",
       "      <th>dateUpdated</th>\n",
       "      <th>descriptions</th>\n",
       "      <th>dimension</th>\n",
       "      <th>ean</th>\n",
       "      <th>flavors</th>\n",
       "      <th>...</th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.userCity</th>\n",
       "      <th>reviews.userProvince</th>\n",
       "      <th>reviews.username</th>\n",
       "      <th>sizes</th>\n",
       "      <th>sourceURLs</th>\n",
       "      <th>upc</th>\n",
       "      <th>weight</th>\n",
       "      <th>primaryCategories</th>\n",
       "      <th>quantities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AV13ClKCGV-KLJ3akN68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gallo</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:11Z</td>\n",
       "      <td>2018-01-10T18:06:28Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0 in x 1.0 in x 1.0 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>My Favorite White Wine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bjh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>4.9213E+11</td>\n",
       "      <td>1.0 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AV13CsvW-jtxr-f38AQO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fresh Craft Co.</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:59:42Z</td>\n",
       "      <td>2018-01-10T05:38:33Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...</td>\n",
       "      <td>4.25 in x 4.25 in x 5.25 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yum!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>83120003441</td>\n",
       "      <td>2.45 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AV13CVI_glJLPUi8O7Po</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000 Stories</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:05Z</td>\n",
       "      <td>2018-01-10T05:38:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3 in x 3.3 in x 11.79 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>A New Favorite!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bama Mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>82896001453</td>\n",
       "      <td>3.09 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AV13CVI_glJLPUi8O7Po</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000 Stories</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:05Z</td>\n",
       "      <td>2018-01-10T05:38:31Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.3 in x 3.3 in x 11.79 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Bold, Flavorful, Aromatic, Delicious</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Av Dub</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://redsky.target.com/v1/plp/search?kwr=y&amp;c...</td>\n",
       "      <td>82896001453</td>\n",
       "      <td>3.09 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AV13CYL4-jtxr-f37_-t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wine Cube153</td>\n",
       "      <td>Food &amp; Beverage,Beverages,Wine, Beer &amp; Liquor,...</td>\n",
       "      <td>2017-07-24T23:58:18Z</td>\n",
       "      <td>2018-01-10T18:06:29Z</td>\n",
       "      <td>[{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...</td>\n",
       "      <td>1.0 in x 1.0 in x 1.0 in</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Yum! Plus, Environmentally Friendly!</td>\n",
       "      <td>Overland Park</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chelseamay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://redsky.target.com/groot-domain-api/v1/...</td>\n",
       "      <td>85200600465</td>\n",
       "      <td>1.0 lbs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id asins            brand  \\\n",
       "0  AV13ClKCGV-KLJ3akN68   NaN            Gallo   \n",
       "1  AV13CsvW-jtxr-f38AQO   NaN  Fresh Craft Co.   \n",
       "2  AV13CVI_glJLPUi8O7Po   NaN     1000 Stories   \n",
       "3  AV13CVI_glJLPUi8O7Po   NaN     1000 Stories   \n",
       "4  AV13CYL4-jtxr-f37_-t   NaN     Wine Cube153   \n",
       "\n",
       "                                          categories             dateAdded  \\\n",
       "0  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:11Z   \n",
       "1  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:59:42Z   \n",
       "2  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:05Z   \n",
       "3  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:05Z   \n",
       "4  Food & Beverage,Beverages,Wine, Beer & Liquor,...  2017-07-24T23:58:18Z   \n",
       "\n",
       "            dateUpdated                                       descriptions  \\\n",
       "0  2018-01-10T18:06:28Z                                                NaN   \n",
       "1  2018-01-10T05:38:33Z  [{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...   \n",
       "2  2018-01-10T05:38:31Z                                                NaN   \n",
       "3  2018-01-10T05:38:31Z                                                NaN   \n",
       "4  2018-01-10T18:06:29Z  [{\"dateSeen\":[\"2017-12-21T05:43:00.000Z\",\"2017...   \n",
       "\n",
       "                     dimension  ean flavors  ...  \\\n",
       "0     1.0 in x 1.0 in x 1.0 in  NaN     NaN  ...   \n",
       "1  4.25 in x 4.25 in x 5.25 in  NaN     NaN  ...   \n",
       "2   3.3 in x 3.3 in x 11.79 in  NaN     NaN  ...   \n",
       "3   3.3 in x 3.3 in x 11.79 in  NaN     NaN  ...   \n",
       "4     1.0 in x 1.0 in x 1.0 in  NaN     NaN  ...   \n",
       "\n",
       "                          reviews.title reviews.userCity reviews.userProvince  \\\n",
       "0                My Favorite White Wine              NaN                  NaN   \n",
       "1                                 Yum!!              NaN                  NaN   \n",
       "2                       A New Favorite!              NaN                  NaN   \n",
       "3  Bold, Flavorful, Aromatic, Delicious              NaN                  NaN   \n",
       "4  Yum! Plus, Environmentally Friendly!    Overland Park                  NaN   \n",
       "\n",
       "  reviews.username sizes                                         sourceURLs  \\\n",
       "0              Bjh   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "1             Wino   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "2         Bama Mom   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "3           Av Dub   NaN  http://redsky.target.com/v1/plp/search?kwr=y&c...   \n",
       "4       Chelseamay   NaN  https://redsky.target.com/groot-domain-api/v1/...   \n",
       "\n",
       "           upc    weight primaryCategories  quantities  \n",
       "0   4.9213E+11   1.0 lbs               NaN         NaN  \n",
       "1  83120003441  2.45 lbs               NaN         NaN  \n",
       "2  82896001453  3.09 lbs               NaN         NaN  \n",
       "3  82896001453  3.09 lbs               NaN         NaN  \n",
       "4  85200600465   1.0 lbs               NaN         NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5f3f218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'asins', 'brand', 'categories', 'dateAdded', 'dateUpdated',\n",
       "       'descriptions', 'dimension', 'ean', 'flavors', 'keys', 'manufacturer',\n",
       "       'manufacturerNumber', 'name', 'reviews.date', 'reviews.dateAdded',\n",
       "       'reviews.dateSeen', 'reviews.didPurchase', 'reviews.doRecommend',\n",
       "       'reviews.id', 'reviews.numHelpful', 'reviews.rating',\n",
       "       'reviews.sourceURLs', 'reviews.text', 'reviews.title',\n",
       "       'reviews.userCity', 'reviews.userProvince', 'reviews.username', 'sizes',\n",
       "       'sourceURLs', 'upc', 'weight', 'primaryCategories', 'quantities'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c54f7ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['primaryCategories', 'quantities']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in wine_reviews_447_1 if item not in wine_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ffc67df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.categories.str.contains('Wine')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bd9ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['name', 'reviews.doRecommend', 'reviews.text', 'reviews.rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63cc1433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data['text'] = df[\"reviews.title\"] + \" \" + df[\"reviews.text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99ebd504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c553fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews.doRecommend'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43a17889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['text', 'reviews.doRecommend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "867440f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data['text'].apply(lambda xyz: clean_doc(xyz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33dc3db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "        ... \n",
       "1212    True\n",
       "1213    True\n",
       "1214    True\n",
       "1215    True\n",
       "1216    True\n",
       "Name: reviews.doRecommend, Length: 2497, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviews.doRecommend']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67b00dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(data['reviews.doRecommend'])\n",
    "data['cat_rec'] = le.transform(data['reviews.doRecommend'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ca5266e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>reviews.doRecommend</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>cat_rec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ecco Domani174 Pinot Grigio - 750ml Bottle</td>\n",
       "      <td>True</td>\n",
       "      <td>This a fantastic white wine for any occasion!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My Favorite White Wine This a fantastic white ...</td>\n",
       "      <td>[my, favorite, white, wine, this, fantastic, w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle</td>\n",
       "      <td>True</td>\n",
       "      <td>Tart, not sweet...very refreshing and delicious!</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yum!! Tart, not sweet...very refreshing and de...</td>\n",
       "      <td>[yum, tart, sweetvery, refreshing, delicious]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
       "      <td>True</td>\n",
       "      <td>I was given this wine so it was a delightful s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A New Favorite! I was given this wine so it wa...</td>\n",
       "      <td>[a, new, favorite, i, given, wine, delightful,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000 Stories174 Zinfandel - 750ml Bottle</td>\n",
       "      <td>True</td>\n",
       "      <td>This is a phenomenal wine and my new favorite ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bold, Flavorful, Aromatic, Delicious This is a...</td>\n",
       "      <td>[bold, flavorful, aromatic, delicious, this, p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pink Moscato - 3l Bottle - Wine Cube153</td>\n",
       "      <td>True</td>\n",
       "      <td>4 750ml bottles for the price of two With way ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yum! Plus, Environmentally Friendly! 4 750ml b...</td>\n",
       "      <td>[yum, plus, environmentally, friendly, 4, 750m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               name reviews.doRecommend  \\\n",
       "0        Ecco Domani174 Pinot Grigio - 750ml Bottle                True   \n",
       "1  Fresh Craft174 Mango Citrus - 4pk / 250ml Bottle                True   \n",
       "2          1000 Stories174 Zinfandel - 750ml Bottle                True   \n",
       "3          1000 Stories174 Zinfandel - 750ml Bottle                True   \n",
       "4           Pink Moscato - 3l Bottle - Wine Cube153                True   \n",
       "\n",
       "                                        reviews.text  reviews.rating  \\\n",
       "0      This a fantastic white wine for any occasion!             5.0   \n",
       "1   Tart, not sweet...very refreshing and delicious!             5.0   \n",
       "2  I was given this wine so it was a delightful s...             5.0   \n",
       "3  This is a phenomenal wine and my new favorite ...             5.0   \n",
       "4  4 750ml bottles for the price of two With way ...             5.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  My Favorite White Wine This a fantastic white ...   \n",
       "1  Yum!! Tart, not sweet...very refreshing and de...   \n",
       "2  A New Favorite! I was given this wine so it wa...   \n",
       "3  Bold, Flavorful, Aromatic, Delicious This is a...   \n",
       "4  Yum! Plus, Environmentally Friendly! 4 750ml b...   \n",
       "\n",
       "                                      processed_text  cat_rec  \n",
       "0  [my, favorite, white, wine, this, fantastic, w...        1  \n",
       "1      [yum, tart, sweetvery, refreshing, delicious]        1  \n",
       "2  [a, new, favorite, i, given, wine, delightful,...        1  \n",
       "3  [bold, flavorful, aromatic, delicious, this, p...        1  \n",
       "4  [yum, plus, environmentally, friendly, 4, 750m...        1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c47845ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rec'] = data['reviews.doRecommend'].apply(lambda absizzle: 'yes' if absizzle==True else 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f208fd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"msds543_chatbotdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "702c7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "datums = []\n",
    "qtown = ['would', 'u', 'buy', 'this', '?']\n",
    "\n",
    "for index, record in data.iterrows():\n",
    "    p_text = record['processed_text']\n",
    "    do_u_rec = record['rec']\n",
    "    tupe_no_dupe = (p_text, qtown, do_u_rec)\n",
    "    datums.append(tupe_no_dupe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0fc20ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(datums, test_size=0.33, \n",
    "                                          random_state=86753-0,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4710251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2497"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1672+825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d001988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1672"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f3a55314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "825"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8c09e1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['great', 'wings', 'my', 'son', 'grandson', 'love', 'wings'],\n",
       " ['would', 'u', 'buy', 'this', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4dc6f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7d7e4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will build a set of all the words in the dataset:\n",
    "vocab = set()\n",
    "for review, question, answer in all_data:\n",
    "    vocab = vocab.union(set(review))\n",
    "    vocab = vocab.union(set(question))\n",
    "\n",
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e5eaef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f53945ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc7eaed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_len = (max(all_reviews_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cd63a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7d2cc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the tokenizer object:\n",
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a07bd33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the stories, questions and answers:\n",
    "train_review_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f6cefabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating each of the elements\n",
    "for review, question, answer in train_data:\n",
    "    train_review_text.append(review)\n",
    "    train_question_text.append(question) \n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4227c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the text into the indexes \n",
    "train_review_seq = tokenizer.texts_to_sequences(train_review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50ba01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for vectorizing the stories, questions and answers:\n",
    "def vectorize_stories(data,word_index = tokenizer.word_index,\n",
    "                      max_review_len = max_review_len, \n",
    "                      max_question_len = max_question_len):\n",
    "    #vectorized stories:\n",
    "    X = []\n",
    "    #vectorized questions:\n",
    "    Xq = []\n",
    "    #vectorized answers:\n",
    "    Y = []\n",
    "    \n",
    "    for review, question, answer in data:\n",
    "        #Getting indexes for each word in the story\n",
    "        x = [word_index[word] for word in review]\n",
    "        #Getting indexes for each word in the story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        #For the answers\n",
    "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #Now we have to pad these sequences:\n",
    "    return(pad_sequences(X,maxlen=max_review_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46370237",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "484990c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d7c166b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0, 4384,  864, 4089, 3525, 3772, 2003,  864],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6a132f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['great', 'wings', 'my', 'son', 'grandson', 'love', 'wings']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f2f565a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4384, 864, 4089, 3525, 3772, 2003, 864]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_review_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c7598e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create the placeholders \n",
    "#The Input function is used to create a keras tensor\n",
    "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
    "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
    "input_sequence = Input((max_review_len,)) #As we dont know batch size yet\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61e2f137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 23:48:19.012327: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#Create input encoder M:\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
    "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6b50e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder C:\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d31466ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create question encoder:\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, question_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bab67fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a0d8fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dot product to compute similarity between input encoded m and question \n",
    "#Like in the paper:\n",
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1b825c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the response we want to add this match with the ouput of input_encoded_c\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0182822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the response we can concatenate it with the question encoded:\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8d213ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 5, 250) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50b55bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the answer tensor with a RNN (LSTM)\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "67d8ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout:\n",
    "answer = Dropout(0.2)(answer)\n",
    "#Output layer:\n",
    "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "14427558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to output a probability distribution for the vocab, using softmax:\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "37377bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the final model:\n",
    "model = Model([input_sequence,question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a06a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#Categorical instead of binary cross entropy as because of the way we are training\n",
    "#we could actually see any of the words from the vocab as output\n",
    "#however, we should only see yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d183c96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 186)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, None, 64)     288448      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, 5, 64)        288448      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 186, 5)       0           ['sequential[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 186, 5)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 5)      22535       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 186, 5)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_1[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 5, 186)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 5, 250)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           36224       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 4507)         148731      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 4507)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 784,386\n",
      "Trainable params: 784,386\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0003cb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "53/53 [==============================] - 5s 35ms/step - loss: 5.9163 - accuracy: 0.9205 - val_loss: 3.7297 - val_accuracy: 0.9370\n",
      "Epoch 2/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 2.2746 - accuracy: 0.9581 - val_loss: 1.0525 - val_accuracy: 0.9370\n",
      "Epoch 3/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.5928 - accuracy: 0.9581 - val_loss: 0.3475 - val_accuracy: 0.9370\n",
      "Epoch 4/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.2463 - accuracy: 0.9581 - val_loss: 0.2739 - val_accuracy: 0.9370\n",
      "Epoch 5/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1930 - accuracy: 0.9581 - val_loss: 0.2505 - val_accuracy: 0.9370\n",
      "Epoch 6/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1817 - accuracy: 0.9581 - val_loss: 0.2436 - val_accuracy: 0.9370\n",
      "Epoch 7/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1759 - accuracy: 0.9581 - val_loss: 0.2419 - val_accuracy: 0.9370\n",
      "Epoch 8/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.1775 - accuracy: 0.9581 - val_loss: 0.2395 - val_accuracy: 0.9370\n",
      "Epoch 9/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.1806 - accuracy: 0.9581 - val_loss: 0.2399 - val_accuracy: 0.9370\n",
      "Epoch 10/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 0.1773 - accuracy: 0.9581 - val_loss: 0.2425 - val_accuracy: 0.9370\n",
      "Epoch 11/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.1756 - accuracy: 0.9581 - val_loss: 0.2421 - val_accuracy: 0.9370\n",
      "Epoch 12/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.1784 - accuracy: 0.9581 - val_loss: 0.2419 - val_accuracy: 0.9370\n",
      "Epoch 13/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.1768 - accuracy: 0.9581 - val_loss: 0.2412 - val_accuracy: 0.9370\n",
      "Epoch 14/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1741 - accuracy: 0.9581 - val_loss: 0.2440 - val_accuracy: 0.9370\n",
      "Epoch 15/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.1749 - accuracy: 0.9581 - val_loss: 0.2391 - val_accuracy: 0.9370\n",
      "Epoch 16/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.1754 - accuracy: 0.9581 - val_loss: 0.2422 - val_accuracy: 0.9370\n",
      "Epoch 17/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 0.1765 - accuracy: 0.9581 - val_loss: 0.2399 - val_accuracy: 0.9370\n",
      "Epoch 18/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.1759 - accuracy: 0.9581 - val_loss: 0.2458 - val_accuracy: 0.9370\n",
      "Epoch 19/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1773 - accuracy: 0.9581 - val_loss: 0.2377 - val_accuracy: 0.9370\n",
      "Epoch 20/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.1772 - accuracy: 0.9581 - val_loss: 0.2411 - val_accuracy: 0.9370\n",
      "Epoch 21/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1790 - accuracy: 0.9581 - val_loss: 0.2417 - val_accuracy: 0.9370\n",
      "Epoch 22/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.1767 - accuracy: 0.9581 - val_loss: 0.2401 - val_accuracy: 0.9370\n",
      "Epoch 23/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.1760 - accuracy: 0.9581 - val_loss: 0.2395 - val_accuracy: 0.9370\n",
      "Epoch 24/1000\n",
      "53/53 [==============================] - 3s 49ms/step - loss: 0.1789 - accuracy: 0.9581 - val_loss: 0.2404 - val_accuracy: 0.9370\n",
      "Epoch 25/1000\n",
      "53/53 [==============================] - 3s 52ms/step - loss: 0.1754 - accuracy: 0.9581 - val_loss: 0.2396 - val_accuracy: 0.9370\n",
      "Epoch 26/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.1752 - accuracy: 0.9581 - val_loss: 0.2398 - val_accuracy: 0.9370\n",
      "Epoch 27/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.1758 - accuracy: 0.9581 - val_loss: 0.2371 - val_accuracy: 0.9370\n",
      "Epoch 28/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1766 - accuracy: 0.9581 - val_loss: 0.2388 - val_accuracy: 0.9370\n",
      "Epoch 29/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1730 - accuracy: 0.9581 - val_loss: 0.2435 - val_accuracy: 0.9370\n",
      "Epoch 30/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1771 - accuracy: 0.9581 - val_loss: 0.2424 - val_accuracy: 0.9370\n",
      "Epoch 31/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.1766 - accuracy: 0.9581 - val_loss: 0.2423 - val_accuracy: 0.9370\n",
      "Epoch 32/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1736 - accuracy: 0.9581 - val_loss: 0.2456 - val_accuracy: 0.9370\n",
      "Epoch 33/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1763 - accuracy: 0.9581 - val_loss: 0.2401 - val_accuracy: 0.9370\n",
      "Epoch 34/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.1750 - accuracy: 0.9581 - val_loss: 0.2456 - val_accuracy: 0.9370\n",
      "Epoch 35/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1775 - accuracy: 0.9581 - val_loss: 0.2387 - val_accuracy: 0.9370\n",
      "Epoch 36/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1756 - accuracy: 0.9581 - val_loss: 0.2377 - val_accuracy: 0.9370\n",
      "Epoch 37/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1776 - accuracy: 0.9581 - val_loss: 0.2433 - val_accuracy: 0.9370\n",
      "Epoch 38/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1737 - accuracy: 0.9581 - val_loss: 0.2464 - val_accuracy: 0.9370\n",
      "Epoch 39/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1764 - accuracy: 0.9581 - val_loss: 0.2415 - val_accuracy: 0.9370\n",
      "Epoch 40/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1754 - accuracy: 0.9581 - val_loss: 0.2434 - val_accuracy: 0.9370\n",
      "Epoch 41/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1770 - accuracy: 0.9581 - val_loss: 0.2454 - val_accuracy: 0.9370\n",
      "Epoch 42/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1759 - accuracy: 0.9581 - val_loss: 0.2356 - val_accuracy: 0.9370\n",
      "Epoch 43/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1756 - accuracy: 0.9581 - val_loss: 0.2430 - val_accuracy: 0.9370\n",
      "Epoch 44/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1760 - accuracy: 0.9581 - val_loss: 0.2402 - val_accuracy: 0.9370\n",
      "Epoch 45/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1750 - accuracy: 0.9581 - val_loss: 0.2358 - val_accuracy: 0.9370\n",
      "Epoch 46/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1743 - accuracy: 0.9581 - val_loss: 0.2317 - val_accuracy: 0.9370\n",
      "Epoch 47/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1670 - accuracy: 0.9581 - val_loss: 0.2215 - val_accuracy: 0.9370\n",
      "Epoch 48/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.1415 - accuracy: 0.9581 - val_loss: 0.2306 - val_accuracy: 0.9370\n",
      "Epoch 49/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1264 - accuracy: 0.9587 - val_loss: 0.1971 - val_accuracy: 0.9370\n",
      "Epoch 50/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.1139 - accuracy: 0.9611 - val_loss: 0.2239 - val_accuracy: 0.9370\n",
      "Epoch 51/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0888 - accuracy: 0.9665 - val_loss: 0.2617 - val_accuracy: 0.9370\n",
      "Epoch 52/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0866 - accuracy: 0.9755 - val_loss: 0.1738 - val_accuracy: 0.9515\n",
      "Epoch 53/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0729 - accuracy: 0.9755 - val_loss: 0.2252 - val_accuracy: 0.9467\n",
      "Epoch 54/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0712 - accuracy: 0.9785 - val_loss: 0.1801 - val_accuracy: 0.9564\n",
      "Epoch 55/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0612 - accuracy: 0.9791 - val_loss: 0.1660 - val_accuracy: 0.9467\n",
      "Epoch 56/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0662 - accuracy: 0.9791 - val_loss: 0.1954 - val_accuracy: 0.9527\n",
      "Epoch 57/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0567 - accuracy: 0.9827 - val_loss: 0.1664 - val_accuracy: 0.9612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0574 - accuracy: 0.9809 - val_loss: 0.1629 - val_accuracy: 0.9600\n",
      "Epoch 59/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0543 - accuracy: 0.9850 - val_loss: 0.1647 - val_accuracy: 0.9661\n",
      "Epoch 60/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0459 - accuracy: 0.9833 - val_loss: 0.1653 - val_accuracy: 0.9624\n",
      "Epoch 61/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.1616 - val_accuracy: 0.9612\n",
      "Epoch 62/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 0.2307 - val_accuracy: 0.9539\n",
      "Epoch 63/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.1870 - val_accuracy: 0.9624\n",
      "Epoch 64/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.0464 - accuracy: 0.9839 - val_loss: 0.1674 - val_accuracy: 0.9636\n",
      "Epoch 65/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0377 - accuracy: 0.9904 - val_loss: 0.1849 - val_accuracy: 0.9648\n",
      "Epoch 66/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.2041 - val_accuracy: 0.9636\n",
      "Epoch 67/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0218 - accuracy: 0.9946 - val_loss: 0.2249 - val_accuracy: 0.9624\n",
      "Epoch 68/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0338 - accuracy: 0.9904 - val_loss: 0.2048 - val_accuracy: 0.9648\n",
      "Epoch 69/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0363 - accuracy: 0.9910 - val_loss: 0.1929 - val_accuracy: 0.9636\n",
      "Epoch 70/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0210 - accuracy: 0.9946 - val_loss: 0.2022 - val_accuracy: 0.9661\n",
      "Epoch 71/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0197 - accuracy: 0.9946 - val_loss: 0.1978 - val_accuracy: 0.9624\n",
      "Epoch 72/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0191 - accuracy: 0.9970 - val_loss: 0.2346 - val_accuracy: 0.9624\n",
      "Epoch 73/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0205 - accuracy: 0.9958 - val_loss: 0.2138 - val_accuracy: 0.9382\n",
      "Epoch 74/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0180 - accuracy: 0.9958 - val_loss: 0.2082 - val_accuracy: 0.9661\n",
      "Epoch 75/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0166 - accuracy: 0.9952 - val_loss: 0.1987 - val_accuracy: 0.9600\n",
      "Epoch 76/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0149 - accuracy: 0.9976 - val_loss: 0.7370 - val_accuracy: 0.7964\n",
      "Epoch 77/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0225 - accuracy: 0.9946 - val_loss: 0.2165 - val_accuracy: 0.9661\n",
      "Epoch 78/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.2249 - val_accuracy: 0.9612\n",
      "Epoch 79/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.2239 - val_accuracy: 0.9624\n",
      "Epoch 80/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.2006 - val_accuracy: 0.9661\n",
      "Epoch 81/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.0128 - accuracy: 0.9970 - val_loss: 0.2124 - val_accuracy: 0.9636\n",
      "Epoch 82/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.2004 - val_accuracy: 0.9636\n",
      "Epoch 83/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.0122 - accuracy: 0.9964 - val_loss: 0.2232 - val_accuracy: 0.9636\n",
      "Epoch 84/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.2522 - val_accuracy: 0.9661\n",
      "Epoch 85/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0114 - accuracy: 0.9970 - val_loss: 0.2673 - val_accuracy: 0.9648\n",
      "Epoch 86/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.2441 - val_accuracy: 0.9636\n",
      "Epoch 87/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.2776 - val_accuracy: 0.9661\n",
      "Epoch 88/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.2779 - val_accuracy: 0.9648\n",
      "Epoch 89/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.3311 - val_accuracy: 0.9600\n",
      "Epoch 90/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 0.2605 - val_accuracy: 0.9648\n",
      "Epoch 91/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.2772 - val_accuracy: 0.9624\n",
      "Epoch 92/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0010 - accuracy: 0.9994 - val_loss: 0.3393 - val_accuracy: 0.9624\n",
      "Epoch 93/1000\n",
      "53/53 [==============================] - 3s 51ms/step - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.3462 - val_accuracy: 0.9624\n",
      "Epoch 94/1000\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 0.0103 - accuracy: 0.9970 - val_loss: 0.2833 - val_accuracy: 0.9648\n",
      "Epoch 95/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.0102 - accuracy: 0.9976 - val_loss: 0.2342 - val_accuracy: 0.9576\n",
      "Epoch 96/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.2644 - val_accuracy: 0.9636\n",
      "Epoch 97/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.2639 - val_accuracy: 0.9648\n",
      "Epoch 98/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.3043 - val_accuracy: 0.9661\n",
      "Epoch 99/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0068 - accuracy: 0.9994 - val_loss: 0.2772 - val_accuracy: 0.9636\n",
      "Epoch 100/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.3102 - val_accuracy: 0.9648\n",
      "Epoch 101/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.2891 - val_accuracy: 0.9624\n",
      "Epoch 102/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.3078 - val_accuracy: 0.9636\n",
      "Epoch 103/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.3234 - val_accuracy: 0.9624\n",
      "Epoch 104/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.2934 - val_accuracy: 0.9648\n",
      "Epoch 105/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.9977e-04 - accuracy: 1.0000 - val_loss: 0.3200 - val_accuracy: 0.9636\n",
      "Epoch 106/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.3358 - val_accuracy: 0.9636\n",
      "Epoch 107/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.3417 - val_accuracy: 0.9648\n",
      "Epoch 108/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.3455 - val_accuracy: 0.9648\n",
      "Epoch 109/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 8.9075e-04 - accuracy: 0.9994 - val_loss: 0.3365 - val_accuracy: 0.9648\n",
      "Epoch 110/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0055 - accuracy: 0.9994 - val_loss: 0.3432 - val_accuracy: 0.9636\n",
      "Epoch 111/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0113 - accuracy: 0.9988 - val_loss: 0.3325 - val_accuracy: 0.9636\n",
      "Epoch 112/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.3267 - val_accuracy: 0.9648\n",
      "Epoch 113/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.0040 - accuracy: 0.9982 - val_loss: 0.3309 - val_accuracy: 0.9636\n",
      "Epoch 114/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.3412 - val_accuracy: 0.9636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.1253e-04 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9636\n",
      "Epoch 116/1000\n",
      "53/53 [==============================] - 3s 48ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.3570 - val_accuracy: 0.9624\n",
      "Epoch 117/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.2201e-04 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9648\n",
      "Epoch 118/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.3879 - val_accuracy: 0.9648\n",
      "Epoch 119/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.3710 - val_accuracy: 0.9600\n",
      "Epoch 120/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.4205 - val_accuracy: 0.9624\n",
      "Epoch 121/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 2.5747e-04 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9636\n",
      "Epoch 122/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 3.6609e-05 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9636\n",
      "Epoch 123/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.4000 - val_accuracy: 0.9624\n",
      "Epoch 124/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 9.2809e-05 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9636\n",
      "Epoch 125/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.4026 - val_accuracy: 0.9636\n",
      "Epoch 126/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 4.2377e-05 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9624\n",
      "Epoch 127/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.3833 - val_accuracy: 0.9624\n",
      "Epoch 128/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.3792 - val_accuracy: 0.9636\n",
      "Epoch 129/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.0342e-04 - accuracy: 0.9994 - val_loss: 0.3870 - val_accuracy: 0.9636\n",
      "Epoch 130/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 2.1235e-05 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9636\n",
      "Epoch 131/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.4395 - val_accuracy: 0.9636\n",
      "Epoch 132/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 2.6998e-05 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9612\n",
      "Epoch 133/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.4552 - val_accuracy: 0.9636\n",
      "Epoch 134/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4228 - val_accuracy: 0.9636\n",
      "Epoch 135/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 3.1722e-05 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9624\n",
      "Epoch 136/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 3.2051e-05 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9624\n",
      "Epoch 137/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.4773 - val_accuracy: 0.9636\n",
      "Epoch 138/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.0427e-05 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9636\n",
      "Epoch 139/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 1.0546e-05 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9612\n",
      "Epoch 140/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 6.5712e-06 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9600\n",
      "Epoch 141/1000\n",
      "53/53 [==============================] - 2s 45ms/step - loss: 7.1781e-06 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.9636\n",
      "Epoch 142/1000\n",
      "53/53 [==============================] - 3s 49ms/step - loss: 0.0110 - accuracy: 0.9988 - val_loss: 0.4945 - val_accuracy: 0.9612\n",
      "Epoch 143/1000\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.5477 - val_accuracy: 0.9612\n",
      "Epoch 144/1000\n",
      "53/53 [==============================] - 4s 69ms/step - loss: 8.7469e-06 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.9612\n",
      "Epoch 145/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 4.6150e-06 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9600\n",
      "Epoch 146/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.5583 - val_accuracy: 0.9612\n",
      "Epoch 147/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.7492e-06 - accuracy: 1.0000 - val_loss: 0.5658 - val_accuracy: 0.9612\n",
      "Epoch 148/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 4.3033e-06 - accuracy: 1.0000 - val_loss: 0.5714 - val_accuracy: 0.9612\n",
      "Epoch 149/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.5734 - val_accuracy: 0.9612\n",
      "Epoch 150/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 3.3495e-06 - accuracy: 1.0000 - val_loss: 0.5722 - val_accuracy: 0.9600\n",
      "Epoch 151/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.5520 - val_accuracy: 0.9612\n",
      "Epoch 152/1000\n",
      "53/53 [==============================] - 2s 47ms/step - loss: 9.7364e-06 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9612\n",
      "Epoch 153/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 4.3985e-06 - accuracy: 1.0000 - val_loss: 0.5806 - val_accuracy: 0.9612\n",
      "Epoch 154/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.3628e-06 - accuracy: 1.0000 - val_loss: 0.5914 - val_accuracy: 0.9612\n",
      "Epoch 155/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.4683e-06 - accuracy: 1.0000 - val_loss: 0.6027 - val_accuracy: 0.9612\n",
      "Epoch 156/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4390e-06 - accuracy: 1.0000 - val_loss: 0.6206 - val_accuracy: 0.9600\n",
      "Epoch 157/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.7964e-07 - accuracy: 1.0000 - val_loss: 0.6435 - val_accuracy: 0.9600\n",
      "Epoch 158/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1560e-06 - accuracy: 1.0000 - val_loss: 0.6286 - val_accuracy: 0.9648\n",
      "Epoch 159/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.0418e-07 - accuracy: 1.0000 - val_loss: 0.6800 - val_accuracy: 0.9636\n",
      "Epoch 160/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.3484e-07 - accuracy: 1.0000 - val_loss: 0.6548 - val_accuracy: 0.9648\n",
      "Epoch 161/1000\n",
      "53/53 [==============================] - 3s 53ms/step - loss: 4.3967e-07 - accuracy: 1.0000 - val_loss: 0.6809 - val_accuracy: 0.9612\n",
      "Epoch 162/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 2.9823e-07 - accuracy: 1.0000 - val_loss: 0.6869 - val_accuracy: 0.9648\n",
      "Epoch 163/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6906 - val_accuracy: 0.9648\n",
      "Epoch 164/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0104 - accuracy: 0.9988 - val_loss: 0.6816 - val_accuracy: 0.9648\n",
      "Epoch 165/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 1.4264e-06 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.9624\n",
      "Epoch 166/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.8396e-07 - accuracy: 1.0000 - val_loss: 0.6836 - val_accuracy: 0.9624\n",
      "Epoch 167/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.6794 - val_accuracy: 0.9648\n",
      "Epoch 168/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.7420 - val_accuracy: 0.9636\n",
      "Epoch 169/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 4.7216e-06 - accuracy: 1.0000 - val_loss: 0.7400 - val_accuracy: 0.9636\n",
      "Epoch 170/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.6683 - val_accuracy: 0.9648\n",
      "Epoch 171/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.7408 - val_accuracy: 0.9636\n",
      "Epoch 172/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.6767 - val_accuracy: 0.9648\n",
      "Epoch 173/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 9.0345e-06 - accuracy: 1.0000 - val_loss: 0.7007 - val_accuracy: 0.9612\n",
      "Epoch 174/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.7254e-06 - accuracy: 1.0000 - val_loss: 0.7008 - val_accuracy: 0.9612\n",
      "Epoch 175/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0070 - accuracy: 0.9988 - val_loss: 0.7221 - val_accuracy: 0.9612\n",
      "Epoch 176/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.0414e-07 - accuracy: 1.0000 - val_loss: 0.7233 - val_accuracy: 0.9612\n",
      "Epoch 177/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 2.7221e-07 - accuracy: 1.0000 - val_loss: 0.7237 - val_accuracy: 0.9612\n",
      "Epoch 178/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 3.2682e-07 - accuracy: 1.0000 - val_loss: 0.7274 - val_accuracy: 0.9612\n",
      "Epoch 179/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 9.6180e-08 - accuracy: 1.0000 - val_loss: 0.7403 - val_accuracy: 0.9612\n",
      "Epoch 180/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 9.8034e-08 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.9612\n",
      "Epoch 181/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.1860e-04 - accuracy: 0.9994 - val_loss: 0.7242 - val_accuracy: 0.9624\n",
      "Epoch 182/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.0217e-07 - accuracy: 1.0000 - val_loss: 0.7252 - val_accuracy: 0.9624\n",
      "Epoch 183/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.1635e-08 - accuracy: 1.0000 - val_loss: 0.7313 - val_accuracy: 0.9624\n",
      "Epoch 184/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 0.0074 - accuracy: 0.9994 - val_loss: 0.7859 - val_accuracy: 0.9636\n",
      "Epoch 185/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 8.2821e-07 - accuracy: 1.0000 - val_loss: 0.7861 - val_accuracy: 0.9636\n",
      "Epoch 186/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7218 - val_accuracy: 0.9648\n",
      "Epoch 187/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0079 - accuracy: 0.9994 - val_loss: 0.7816 - val_accuracy: 0.9636\n",
      "Epoch 188/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.7199 - val_accuracy: 0.9624\n",
      "Epoch 189/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 2.2992e-06 - accuracy: 1.0000 - val_loss: 0.7552 - val_accuracy: 0.9600\n",
      "Epoch 190/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.2798e-07 - accuracy: 1.0000 - val_loss: 0.7558 - val_accuracy: 0.9600\n",
      "Epoch 191/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.8501e-07 - accuracy: 1.0000 - val_loss: 0.7631 - val_accuracy: 0.9600\n",
      "Epoch 192/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.1365e-07 - accuracy: 1.0000 - val_loss: 0.7680 - val_accuracy: 0.9600\n",
      "Epoch 193/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 9.6394e-08 - accuracy: 1.0000 - val_loss: 0.7941 - val_accuracy: 0.9600\n",
      "Epoch 194/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 3.5791e-08 - accuracy: 1.0000 - val_loss: 0.8046 - val_accuracy: 0.9612\n",
      "Epoch 195/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.2868e-08 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.9612\n",
      "Epoch 196/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.9641e-08 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.9600\n",
      "Epoch 197/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.2440e-08 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.9636\n",
      "Epoch 198/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 6.2242e-08 - accuracy: 1.0000 - val_loss: 0.8284 - val_accuracy: 0.9636\n",
      "Epoch 199/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.4752e-05 - accuracy: 1.0000 - val_loss: 0.7834 - val_accuracy: 0.9600\n",
      "Epoch 200/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0094 - accuracy: 0.9994 - val_loss: 0.8286 - val_accuracy: 0.9636\n",
      "Epoch 201/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 5.7822e-08 - accuracy: 1.0000 - val_loss: 0.8280 - val_accuracy: 0.9636\n",
      "Epoch 202/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 5.4471e-08 - accuracy: 1.0000 - val_loss: 0.8292 - val_accuracy: 0.9636\n",
      "Epoch 203/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.8500e-08 - accuracy: 1.0000 - val_loss: 0.8303 - val_accuracy: 0.9636\n",
      "Epoch 204/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.8838e-08 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.9636\n",
      "Epoch 205/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.9042e-07 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.9648\n",
      "Epoch 206/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.7502e-08 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.9600\n",
      "Epoch 207/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0170 - accuracy: 0.9988 - val_loss: 0.8142 - val_accuracy: 0.9600\n",
      "Epoch 208/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.9942e-08 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 0.9600\n",
      "Epoch 209/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8662e-08 - accuracy: 1.0000 - val_loss: 0.8163 - val_accuracy: 0.9612\n",
      "Epoch 210/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-08 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.9612\n",
      "Epoch 211/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.8767e-08 - accuracy: 1.0000 - val_loss: 0.8196 - val_accuracy: 0.9612\n",
      "Epoch 212/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.8535e-07 - accuracy: 1.0000 - val_loss: 0.7986 - val_accuracy: 0.9624\n",
      "Epoch 213/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 4.4119e-06 - accuracy: 1.0000 - val_loss: 0.8556 - val_accuracy: 0.9636\n",
      "Epoch 214/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0158 - accuracy: 0.9994 - val_loss: 0.8087 - val_accuracy: 0.9600\n",
      "Epoch 215/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.1814e-08 - accuracy: 1.0000 - val_loss: 0.8084 - val_accuracy: 0.9600\n",
      "Epoch 216/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.4760e-06 - accuracy: 1.0000 - val_loss: 0.8067 - val_accuracy: 0.9612\n",
      "Epoch 217/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 3.1513e-08 - accuracy: 1.0000 - val_loss: 0.8077 - val_accuracy: 0.9612\n",
      "Epoch 218/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.4365e-08 - accuracy: 1.0000 - val_loss: 0.8340 - val_accuracy: 0.9600\n",
      "Epoch 219/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0196e-08 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.9600\n",
      "Epoch 220/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.0912e-06 - accuracy: 1.0000 - val_loss: 0.8529 - val_accuracy: 0.9636\n",
      "Epoch 221/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.8408 - val_accuracy: 0.9612\n",
      "Epoch 222/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1336e-08 - accuracy: 1.0000 - val_loss: 0.8416 - val_accuracy: 0.9612\n",
      "Epoch 223/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5221e-08 - accuracy: 1.0000 - val_loss: 0.8439 - val_accuracy: 0.9612\n",
      "Epoch 224/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 3.2297e-08 - accuracy: 1.0000 - val_loss: 0.8532 - val_accuracy: 0.9612\n",
      "Epoch 225/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 40ms/step - loss: 3.6148e-08 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.9600\n",
      "Epoch 226/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.8543 - val_accuracy: 0.9612\n",
      "Epoch 227/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 1.5258e-08 - accuracy: 1.0000 - val_loss: 0.8545 - val_accuracy: 0.9612\n",
      "Epoch 228/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 2.5881e-08 - accuracy: 1.0000 - val_loss: 0.8550 - val_accuracy: 0.9612\n",
      "Epoch 229/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.5356e-07 - accuracy: 1.0000 - val_loss: 0.8593 - val_accuracy: 0.9612\n",
      "Epoch 230/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 4.5701e-08 - accuracy: 1.0000 - val_loss: 0.8612 - val_accuracy: 0.9612\n",
      "Epoch 231/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 5.8748e-08 - accuracy: 1.0000 - val_loss: 0.8777 - val_accuracy: 0.9624\n",
      "Epoch 232/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.8028 - val_accuracy: 0.9636\n",
      "Epoch 233/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.8728 - val_accuracy: 0.9636\n",
      "Epoch 234/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 1.2477e-08 - accuracy: 1.0000 - val_loss: 0.8729 - val_accuracy: 0.9636\n",
      "Epoch 235/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.3974e-07 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.9624\n",
      "Epoch 236/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 9.7677e-09 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.9624\n",
      "Epoch 237/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 9.0548e-09 - accuracy: 1.0000 - val_loss: 0.8800 - val_accuracy: 0.9624\n",
      "Epoch 238/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.7961 - val_accuracy: 0.9636\n",
      "Epoch 239/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 4.0779e-06 - accuracy: 1.0000 - val_loss: 0.8168 - val_accuracy: 0.9624\n",
      "Epoch 240/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.8564 - val_accuracy: 0.9636\n",
      "Epoch 241/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.7930 - val_accuracy: 0.9624\n",
      "Epoch 242/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.8488 - val_accuracy: 0.9636\n",
      "Epoch 243/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.5472e-08 - accuracy: 1.0000 - val_loss: 0.8488 - val_accuracy: 0.9636\n",
      "Epoch 244/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.7854e-08 - accuracy: 1.0000 - val_loss: 0.8494 - val_accuracy: 0.9636\n",
      "Epoch 245/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.6309e-08 - accuracy: 1.0000 - val_loss: 0.8540 - val_accuracy: 0.9636\n",
      "Epoch 246/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.9122e-09 - accuracy: 1.0000 - val_loss: 0.8603 - val_accuracy: 0.9636\n",
      "Epoch 247/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 3.8072e-08 - accuracy: 1.0000 - val_loss: 0.8723 - val_accuracy: 0.9636\n",
      "Epoch 248/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.3171e-08 - accuracy: 1.0000 - val_loss: 0.8749 - val_accuracy: 0.9636\n",
      "Epoch 249/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 5.9890e-09 - accuracy: 1.0000 - val_loss: 0.8822 - val_accuracy: 0.9636\n",
      "Epoch 250/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.8183 - val_accuracy: 0.9648\n",
      "Epoch 251/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 1.3689e-08 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.9648\n",
      "Epoch 252/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 3.3937e-08 - accuracy: 1.0000 - val_loss: 0.8188 - val_accuracy: 0.9648\n",
      "Epoch 253/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0339e-06 - accuracy: 1.0000 - val_loss: 0.8955 - val_accuracy: 0.9636\n",
      "Epoch 254/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 1.8008e-07 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.9648\n",
      "Epoch 255/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.5543e-08 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.9624\n",
      "Epoch 256/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.9158e-09 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.9624\n",
      "Epoch 257/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 8.0278e-08 - accuracy: 1.0000 - val_loss: 0.8450 - val_accuracy: 0.9612\n",
      "Epoch 258/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.9036e-08 - accuracy: 1.0000 - val_loss: 0.8604 - val_accuracy: 0.9612\n",
      "Epoch 259/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.6683e-08 - accuracy: 1.0000 - val_loss: 0.8639 - val_accuracy: 0.9612\n",
      "Epoch 260/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 6.0603e-09 - accuracy: 1.0000 - val_loss: 0.8642 - val_accuracy: 0.9612\n",
      "Epoch 261/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.3473e-09 - accuracy: 1.0000 - val_loss: 0.8653 - val_accuracy: 0.9612\n",
      "Epoch 262/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 6.4664e-08 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.9636\n",
      "Epoch 263/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0089 - accuracy: 0.9994 - val_loss: 0.8912 - val_accuracy: 0.9600\n",
      "Epoch 264/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 3.2155e-08 - accuracy: 1.0000 - val_loss: 0.8925 - val_accuracy: 0.9600\n",
      "Epoch 265/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1408e-08 - accuracy: 1.0000 - val_loss: 0.8929 - val_accuracy: 0.9600\n",
      "Epoch 266/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 5.8537e-07 - accuracy: 1.0000 - val_loss: 0.9160 - val_accuracy: 0.9636\n",
      "Epoch 267/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.3385e-08 - accuracy: 1.0000 - val_loss: 0.9009 - val_accuracy: 0.9612\n",
      "Epoch 268/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.0177e-08 - accuracy: 1.0000 - val_loss: 0.9017 - val_accuracy: 0.9612\n",
      "Epoch 269/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 0.9047 - val_accuracy: 0.9612\n",
      "Epoch 270/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4241e-08 - accuracy: 1.0000 - val_loss: 0.9031 - val_accuracy: 0.9612\n",
      "Epoch 271/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.9927e-09 - accuracy: 1.0000 - val_loss: 0.9027 - val_accuracy: 0.9600\n",
      "Epoch 272/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.7019e-09 - accuracy: 1.0000 - val_loss: 0.8989 - val_accuracy: 0.9612\n",
      "Epoch 273/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.4917e-09 - accuracy: 1.0000 - val_loss: 0.8971 - val_accuracy: 0.9612\n",
      "Epoch 274/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1122e-08 - accuracy: 1.0000 - val_loss: 0.8976 - val_accuracy: 0.9612\n",
      "Epoch 275/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.7001e-09 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 0.9612\n",
      "Epoch 276/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.3333e-08 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.9636\n",
      "Epoch 277/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.2470e-05 - accuracy: 1.0000 - val_loss: 0.8634 - val_accuracy: 0.9648\n",
      "Epoch 278/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 7.5575e-09 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.9648\n",
      "Epoch 279/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.7038e-09 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.9648\n",
      "Epoch 280/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.6003e-04 - accuracy: 1.0000 - val_loss: 0.9366 - val_accuracy: 0.9636\n",
      "Epoch 281/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0169 - accuracy: 0.9994 - val_loss: 0.8773 - val_accuracy: 0.9612\n",
      "Epoch 282/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.9167 - val_accuracy: 0.9612\n",
      "Epoch 283/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.3473e-09 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.9612\n",
      "Epoch 284/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.2958e-08 - accuracy: 1.0000 - val_loss: 0.9167 - val_accuracy: 0.9612\n",
      "Epoch 285/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1336e-08 - accuracy: 1.0000 - val_loss: 0.9168 - val_accuracy: 0.9612\n",
      "Epoch 286/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.0621e-09 - accuracy: 1.0000 - val_loss: 0.9181 - val_accuracy: 0.9612\n",
      "Epoch 287/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.0124e-08 - accuracy: 1.0000 - val_loss: 0.9217 - val_accuracy: 0.9612\n",
      "Epoch 288/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.5258e-08 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.9612\n",
      "Epoch 289/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.1051e-08 - accuracy: 1.0000 - val_loss: 0.9071 - val_accuracy: 0.9600\n",
      "Epoch 290/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.5828e-08 - accuracy: 1.0000 - val_loss: 0.9472 - val_accuracy: 0.9636\n",
      "Epoch 291/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-09 - accuracy: 1.0000 - val_loss: 0.9486 - val_accuracy: 0.9636\n",
      "Epoch 292/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.4092e-07 - accuracy: 1.0000 - val_loss: 0.8827 - val_accuracy: 0.9600\n",
      "Epoch 293/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0279e-06 - accuracy: 1.0000 - val_loss: 0.9604 - val_accuracy: 0.9624\n",
      "Epoch 294/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.9177e-09 - accuracy: 1.0000 - val_loss: 0.9614 - val_accuracy: 0.9624\n",
      "Epoch 295/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.9624\n",
      "Epoch 296/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0125 - accuracy: 0.9994 - val_loss: 0.8839 - val_accuracy: 0.9600\n",
      "Epoch 297/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 9.8539e-05 - accuracy: 1.0000 - val_loss: 0.9511 - val_accuracy: 0.9612\n",
      "Epoch 298/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.4972e-08 - accuracy: 1.0000 - val_loss: 0.9513 - val_accuracy: 0.9612\n",
      "Epoch 299/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 9.2686e-09 - accuracy: 1.0000 - val_loss: 0.9516 - val_accuracy: 0.9612\n",
      "Epoch 300/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.9519 - val_accuracy: 0.9612\n",
      "Epoch 301/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 9.3399e-09 - accuracy: 1.0000 - val_loss: 0.9527 - val_accuracy: 0.9612\n",
      "Epoch 302/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 5.4899e-09 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.9612\n",
      "Epoch 303/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.3473e-09 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.9612\n",
      "Epoch 304/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.5685e-08 - accuracy: 1.0000 - val_loss: 0.9542 - val_accuracy: 0.9612\n",
      "Epoch 305/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 7.5072e-08 - accuracy: 1.0000 - val_loss: 0.9317 - val_accuracy: 0.9612\n",
      "Epoch 306/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.9853e-09 - accuracy: 1.0000 - val_loss: 0.9350 - val_accuracy: 0.9612\n",
      "Epoch 307/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9347 - val_accuracy: 0.9612\n",
      "Epoch 308/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 0.9368 - val_accuracy: 0.9612\n",
      "Epoch 309/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9371 - val_accuracy: 0.9612\n",
      "Epoch 310/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 8.4844e-09 - accuracy: 1.0000 - val_loss: 0.9303 - val_accuracy: 0.9600\n",
      "Epoch 311/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.3491e-09 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.9600\n",
      "Epoch 312/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.5630e-09 - accuracy: 1.0000 - val_loss: 0.9253 - val_accuracy: 0.9588\n",
      "Epoch 313/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 0.9259 - val_accuracy: 0.9588\n",
      "Epoch 314/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.9393e-08 - accuracy: 1.0000 - val_loss: 0.9169 - val_accuracy: 0.9612\n",
      "Epoch 315/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.7111e-08 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 0.9612\n",
      "Epoch 316/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 1.6755e-08 - accuracy: 1.0000 - val_loss: 0.9183 - val_accuracy: 0.9612\n",
      "Epoch 317/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 4.3491e-09 - accuracy: 1.0000 - val_loss: 0.9177 - val_accuracy: 0.9612\n",
      "Epoch 318/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.9664 - val_accuracy: 0.9636\n",
      "Epoch 319/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 0.9665 - val_accuracy: 0.9636\n",
      "Epoch 320/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.0639e-09 - accuracy: 1.0000 - val_loss: 0.9664 - val_accuracy: 0.9636\n",
      "Epoch 321/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.3333e-08 - accuracy: 1.0000 - val_loss: 0.9674 - val_accuracy: 0.9636\n",
      "Epoch 322/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 6.6161e-08 - accuracy: 1.0000 - val_loss: 0.9267 - val_accuracy: 0.9612\n",
      "Epoch 323/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 0.9272 - val_accuracy: 0.9612\n",
      "Epoch 324/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.6042e-08 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.9636\n",
      "Epoch 325/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 9.3399e-09 - accuracy: 1.0000 - val_loss: 0.9796 - val_accuracy: 0.9624\n",
      "Epoch 326/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 3.7788e-09 - accuracy: 1.0000 - val_loss: 0.9809 - val_accuracy: 0.9624\n",
      "Epoch 327/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 9.5538e-09 - accuracy: 1.0000 - val_loss: 0.9820 - val_accuracy: 0.9624\n",
      "Epoch 328/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 5.2047e-09 - accuracy: 1.0000 - val_loss: 0.9813 - val_accuracy: 0.9624\n",
      "Epoch 329/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.5258e-08 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 0.9624\n",
      "Epoch 330/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 6.9158e-09 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.9624\n",
      "Epoch 331/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1194e-08 - accuracy: 1.0000 - val_loss: 0.9864 - val_accuracy: 0.9624\n",
      "Epoch 332/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 0.9854 - val_accuracy: 0.9624\n",
      "Epoch 333/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 4.3491e-09 - accuracy: 1.0000 - val_loss: 0.9850 - val_accuracy: 0.9624\n",
      "Epoch 334/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 2.8019e-08 - accuracy: 1.0000 - val_loss: 0.9507 - val_accuracy: 0.9612\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 33ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.9612\n",
      "Epoch 336/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 9.1973e-09 - accuracy: 1.0000 - val_loss: 0.9462 - val_accuracy: 0.9600\n",
      "Epoch 337/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.9463 - val_accuracy: 0.9600\n",
      "Epoch 338/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 0.9466 - val_accuracy: 0.9600\n",
      "Epoch 339/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.2760e-09 - accuracy: 1.0000 - val_loss: 0.9479 - val_accuracy: 0.9588\n",
      "Epoch 340/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.8390e-09 - accuracy: 1.0000 - val_loss: 0.9515 - val_accuracy: 0.9600\n",
      "Epoch 341/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 0.9522 - val_accuracy: 0.9600\n",
      "Epoch 342/1000\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.9600\n",
      "Epoch 343/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 4.2065e-09 - accuracy: 1.0000 - val_loss: 0.9540 - val_accuracy: 0.9600\n",
      "Epoch 344/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 1.5186e-08 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.9588\n",
      "Epoch 345/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 2.5168e-08 - accuracy: 1.0000 - val_loss: 0.9573 - val_accuracy: 0.9588\n",
      "Epoch 346/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9577 - val_accuracy: 0.9588\n",
      "Epoch 347/1000\n",
      "53/53 [==============================] - 3s 49ms/step - loss: 8.4131e-09 - accuracy: 1.0000 - val_loss: 0.9605 - val_accuracy: 0.9588\n",
      "Epoch 348/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0110 - accuracy: 0.9994 - val_loss: 0.9853 - val_accuracy: 0.9624\n",
      "Epoch 349/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.8822e-08 - accuracy: 1.0000 - val_loss: 0.9837 - val_accuracy: 0.9624\n",
      "Epoch 350/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 0.9836 - val_accuracy: 0.9624\n",
      "Epoch 351/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 0.0082 - accuracy: 0.9994 - val_loss: 0.8794 - val_accuracy: 0.9624\n",
      "Epoch 352/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0291 - accuracy: 0.9988 - val_loss: 0.9587 - val_accuracy: 0.9624\n",
      "Epoch 353/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 3.3866e-08 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.9624\n",
      "Epoch 354/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 5.7751e-09 - accuracy: 1.0000 - val_loss: 0.9588 - val_accuracy: 0.9624\n",
      "Epoch 355/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 6.6307e-09 - accuracy: 1.0000 - val_loss: 0.9591 - val_accuracy: 0.9624\n",
      "Epoch 356/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 3.8642e-08 - accuracy: 1.0000 - val_loss: 0.9619 - val_accuracy: 0.9624\n",
      "Epoch 357/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 2.2102e-09 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.9624\n",
      "Epoch 358/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 2.4098e-08 - accuracy: 1.0000 - val_loss: 0.9729 - val_accuracy: 0.9624\n",
      "Epoch 359/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0214 - accuracy: 0.9988 - val_loss: 0.8633 - val_accuracy: 0.9648\n",
      "Epoch 360/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0156 - accuracy: 0.9988 - val_loss: 0.8313 - val_accuracy: 0.9624\n",
      "Epoch 361/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.3846e-06 - accuracy: 1.0000 - val_loss: 0.8341 - val_accuracy: 0.9624\n",
      "Epoch 362/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 7.7001e-09 - accuracy: 1.0000 - val_loss: 0.8342 - val_accuracy: 0.9624\n",
      "Epoch 363/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 2.9945e-08 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.9624\n",
      "Epoch 364/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 7.6214e-08 - accuracy: 1.0000 - val_loss: 0.8412 - val_accuracy: 0.9624\n",
      "Epoch 365/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.6541e-08 - accuracy: 1.0000 - val_loss: 0.8668 - val_accuracy: 0.9612\n",
      "Epoch 366/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.2815e-09 - accuracy: 1.0000 - val_loss: 0.8685 - val_accuracy: 0.9612\n",
      "Epoch 367/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.9816e-09 - accuracy: 1.0000 - val_loss: 0.8683 - val_accuracy: 0.9624\n",
      "Epoch 368/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.6090e-07 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.9636\n",
      "Epoch 369/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 7.6284e-08 - accuracy: 1.0000 - val_loss: 0.9146 - val_accuracy: 0.9612\n",
      "Epoch 370/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 2.9160e-08 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 0.9636\n",
      "Epoch 371/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.8991 - val_accuracy: 0.9612\n",
      "Epoch 372/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 1.2691e-08 - accuracy: 1.0000 - val_loss: 0.9009 - val_accuracy: 0.9612\n",
      "Epoch 373/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 9.2686e-09 - accuracy: 1.0000 - val_loss: 0.9019 - val_accuracy: 0.9612\n",
      "Epoch 374/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.1297e-09 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.9612\n",
      "Epoch 375/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 2.5667e-09 - accuracy: 1.0000 - val_loss: 0.9055 - val_accuracy: 0.9612\n",
      "Epoch 376/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 0.9061 - val_accuracy: 0.9624\n",
      "Epoch 377/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 6.8585e-08 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9624\n",
      "Epoch 378/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 1.8395e-08 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.9624\n",
      "Epoch 379/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.8807 - val_accuracy: 0.9624\n",
      "Epoch 380/1000\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 9.9239e-08 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.9624\n",
      "Epoch 381/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 0.8810 - val_accuracy: 0.9624\n",
      "Epoch 382/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 7.1263e-05 - accuracy: 1.0000 - val_loss: 0.9468 - val_accuracy: 0.9636\n",
      "Epoch 383/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.5667e-08 - accuracy: 1.0000 - val_loss: 0.9476 - val_accuracy: 0.9636\n",
      "Epoch 384/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1051e-08 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.9636\n",
      "Epoch 385/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.1123e-07 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.9624\n",
      "Epoch 386/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 5.2080e-04 - accuracy: 0.9994 - val_loss: 0.9641 - val_accuracy: 0.9636\n",
      "Epoch 387/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.9892e-08 - accuracy: 1.0000 - val_loss: 0.9661 - val_accuracy: 0.9636\n",
      "Epoch 388/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.3742e-08 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 0.9636\n",
      "Epoch 389/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.2999e-04 - accuracy: 0.9994 - val_loss: 0.8790 - val_accuracy: 0.9624\n",
      "Epoch 390/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 0.9633 - val_accuracy: 0.9636\n",
      "Epoch 391/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 9.6320e-08 - accuracy: 1.0000 - val_loss: 0.9629 - val_accuracy: 0.9636\n",
      "Epoch 392/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.0756e-08 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 0.9636\n",
      "Epoch 393/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 4.4917e-09 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9636\n",
      "Epoch 394/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 4.4917e-09 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.9636\n",
      "Epoch 395/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 0.0079 - accuracy: 0.9988 - val_loss: 0.9417 - val_accuracy: 0.9624\n",
      "Epoch 396/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 0.9417 - val_accuracy: 0.9624\n",
      "Epoch 397/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 3.2226e-08 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.9624\n",
      "Epoch 398/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.7895e-08 - accuracy: 1.0000 - val_loss: 0.9421 - val_accuracy: 0.9624\n",
      "Epoch 399/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 3.8501e-09 - accuracy: 1.0000 - val_loss: 0.9435 - val_accuracy: 0.9624\n",
      "Epoch 400/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.8409e-09 - accuracy: 1.0000 - val_loss: 0.9424 - val_accuracy: 0.9624\n",
      "Epoch 401/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.6380e-09 - accuracy: 1.0000 - val_loss: 0.9414 - val_accuracy: 0.9624\n",
      "Epoch 402/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.7610e-08 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.9624\n",
      "Epoch 403/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.4592e-08 - accuracy: 1.0000 - val_loss: 0.9022 - val_accuracy: 0.9612\n",
      "Epoch 404/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 0.9026 - val_accuracy: 0.9612\n",
      "Epoch 405/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.6380e-09 - accuracy: 1.0000 - val_loss: 0.9039 - val_accuracy: 0.9612\n",
      "Epoch 406/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 0.8999 - val_accuracy: 0.9612\n",
      "Epoch 407/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 0.9004 - val_accuracy: 0.9612\n",
      "Epoch 408/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.8482e-09 - accuracy: 1.0000 - val_loss: 0.9023 - val_accuracy: 0.9612\n",
      "Epoch 409/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 3.6693e-07 - accuracy: 1.0000 - val_loss: 0.9849 - val_accuracy: 0.9636\n",
      "Epoch 410/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.8859 - val_accuracy: 0.9612\n",
      "Epoch 411/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 6.2029e-09 - accuracy: 1.0000 - val_loss: 0.8861 - val_accuracy: 0.9612\n",
      "Epoch 412/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 3.0396e-06 - accuracy: 1.0000 - val_loss: 0.9077 - val_accuracy: 0.9624\n",
      "Epoch 413/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.9912 - val_accuracy: 0.9636\n",
      "Epoch 414/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 0.9912 - val_accuracy: 0.9636\n",
      "Epoch 415/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 6.5593e-09 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 0.9636\n",
      "Epoch 416/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.0049 - accuracy: 0.9994 - val_loss: 0.9247 - val_accuracy: 0.9624\n",
      "Epoch 417/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 3.1371e-09 - accuracy: 1.0000 - val_loss: 0.9248 - val_accuracy: 0.9624\n",
      "Epoch 418/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.6254e-07 - accuracy: 1.0000 - val_loss: 0.9525 - val_accuracy: 0.9600\n",
      "Epoch 419/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 1.0338e-08 - accuracy: 1.0000 - val_loss: 0.9534 - val_accuracy: 0.9600\n",
      "Epoch 420/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.2815e-09 - accuracy: 1.0000 - val_loss: 0.9551 - val_accuracy: 0.9600\n",
      "Epoch 421/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 3.2797e-09 - accuracy: 1.0000 - val_loss: 0.9557 - val_accuracy: 0.9600\n",
      "Epoch 422/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 2.9945e-09 - accuracy: 1.0000 - val_loss: 0.9533 - val_accuracy: 0.9600\n",
      "Epoch 423/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 0.9532 - val_accuracy: 0.9612\n",
      "Epoch 424/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 7.2010e-09 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.9600\n",
      "Epoch 425/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 0.9514 - val_accuracy: 0.9600\n",
      "Epoch 426/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 2.8519e-09 - accuracy: 1.0000 - val_loss: 0.9537 - val_accuracy: 0.9600\n",
      "Epoch 427/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 0.9547 - val_accuracy: 0.9600\n",
      "Epoch 428/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.5329e-08 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.9600\n",
      "Epoch 429/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.5649e-09 - accuracy: 1.0000 - val_loss: 0.9552 - val_accuracy: 0.9600\n",
      "Epoch 430/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 0.9419 - val_accuracy: 0.9612\n",
      "Epoch 431/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.9612\n",
      "Epoch 432/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 3.7075e-09 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.9612\n",
      "Epoch 433/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 3.0690e-04 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.9636\n",
      "Epoch 434/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.9636\n",
      "Epoch 435/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 9.6672e-08 - accuracy: 1.0000 - val_loss: 1.0073 - val_accuracy: 0.9636\n",
      "Epoch 436/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.0109 - accuracy: 0.9994 - val_loss: 0.9289 - val_accuracy: 0.9612\n",
      "Epoch 437/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9293 - val_accuracy: 0.9612\n",
      "Epoch 438/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 4.7056e-09 - accuracy: 1.0000 - val_loss: 0.9297 - val_accuracy: 0.9612\n",
      "Epoch 439/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 9.3399e-09 - accuracy: 1.0000 - val_loss: 0.9304 - val_accuracy: 0.9612\n",
      "Epoch 440/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.4881e-09 - accuracy: 1.0000 - val_loss: 0.9306 - val_accuracy: 0.9612\n",
      "Epoch 441/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.3899e-08 - accuracy: 1.0000 - val_loss: 1.0010 - val_accuracy: 0.9624\n",
      "Epoch 442/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.9624\n",
      "Epoch 443/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-08 - accuracy: 1.0000 - val_loss: 0.9377 - val_accuracy: 0.9624\n",
      "Epoch 444/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.4578e-08 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 0.9624\n",
      "Epoch 445/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 25ms/step - loss: 8.2705e-09 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.9624\n",
      "Epoch 446/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 0.9637 - val_accuracy: 0.9624\n",
      "Epoch 447/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 2.9764e-04 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.9636\n",
      "Epoch 448/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 0.9901 - val_accuracy: 0.9636\n",
      "Epoch 449/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.6995e-05 - accuracy: 1.0000 - val_loss: 0.9616 - val_accuracy: 0.9624\n",
      "Epoch 450/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.9624\n",
      "Epoch 451/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.6306e-09 - accuracy: 1.0000 - val_loss: 0.9621 - val_accuracy: 0.9624\n",
      "Epoch 452/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9624\n",
      "Epoch 453/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 0.9624\n",
      "Epoch 454/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.8464e-09 - accuracy: 1.0000 - val_loss: 0.9688 - val_accuracy: 0.9624\n",
      "Epoch 455/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.6380e-09 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 0.9624\n",
      "Epoch 456/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 0.9704 - val_accuracy: 0.9624\n",
      "Epoch 457/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.7769e-09 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 0.9624\n",
      "Epoch 458/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 0.9738 - val_accuracy: 0.9624\n",
      "Epoch 459/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9744 - val_accuracy: 0.9624\n",
      "Epoch 460/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 0.9745 - val_accuracy: 0.9624\n",
      "Epoch 461/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.7806e-09 - accuracy: 1.0000 - val_loss: 0.9756 - val_accuracy: 0.9612\n",
      "Epoch 462/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0130 - accuracy: 0.9988 - val_loss: 0.9721 - val_accuracy: 0.9612\n",
      "Epoch 463/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.6256e-08 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.9612\n",
      "Epoch 464/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9721 - val_accuracy: 0.9612\n",
      "Epoch 465/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 0.9722 - val_accuracy: 0.9612\n",
      "Epoch 466/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.6982e-09 - accuracy: 1.0000 - val_loss: 0.9730 - val_accuracy: 0.9612\n",
      "Epoch 467/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.2548e-08 - accuracy: 1.0000 - val_loss: 0.9752 - val_accuracy: 0.9612\n",
      "Epoch 468/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.6461e-07 - accuracy: 1.0000 - val_loss: 1.0121 - val_accuracy: 0.9624\n",
      "Epoch 469/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.9624\n",
      "Epoch 470/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.2102e-09 - accuracy: 1.0000 - val_loss: 1.0127 - val_accuracy: 0.9624\n",
      "Epoch 471/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-09 - accuracy: 1.0000 - val_loss: 1.0128 - val_accuracy: 0.9624\n",
      "Epoch 472/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.4223e-09 - accuracy: 1.0000 - val_loss: 1.0117 - val_accuracy: 0.9624\n",
      "Epoch 473/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0113 - val_accuracy: 0.9624\n",
      "Epoch 474/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.2047e-09 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.9624\n",
      "Epoch 475/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0111 - accuracy: 0.9994 - val_loss: 0.9311 - val_accuracy: 0.9600\n",
      "Epoch 476/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0141 - accuracy: 0.9994 - val_loss: 0.9319 - val_accuracy: 0.9612\n",
      "Epoch 477/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.8464e-09 - accuracy: 1.0000 - val_loss: 0.9320 - val_accuracy: 0.9612\n",
      "Epoch 478/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.9195e-09 - accuracy: 1.0000 - val_loss: 0.9321 - val_accuracy: 0.9612\n",
      "Epoch 479/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.3510e-09 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.9612\n",
      "Epoch 480/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.7714e-09 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.9612\n",
      "Epoch 481/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 0.9445 - val_accuracy: 0.9612\n",
      "Epoch 482/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-09 - accuracy: 1.0000 - val_loss: 0.9412 - val_accuracy: 0.9612\n",
      "Epoch 483/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 0.9612\n",
      "Epoch 484/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.7087e-08 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.9612\n",
      "Epoch 485/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 0.9825 - val_accuracy: 0.9612\n",
      "Epoch 486/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 0.9826 - val_accuracy: 0.9612\n",
      "Epoch 487/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.0016e-08 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9600\n",
      "Epoch 488/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.2742e-09 - accuracy: 1.0000 - val_loss: 0.9606 - val_accuracy: 0.9600\n",
      "Epoch 489/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 0.9610 - val_accuracy: 0.9600\n",
      "Epoch 490/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 0.9636 - val_accuracy: 0.9600\n",
      "Epoch 491/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 0.9640 - val_accuracy: 0.9612\n",
      "Epoch 492/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.3385e-08 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.9612\n",
      "Epoch 493/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0046 - accuracy: 0.9994 - val_loss: 0.9970 - val_accuracy: 0.9624\n",
      "Epoch 494/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 0.9972 - val_accuracy: 0.9624\n",
      "Epoch 495/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 6.3729e-06 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9612\n",
      "Epoch 496/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9612\n",
      "Epoch 497/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.2601e-08 - accuracy: 1.0000 - val_loss: 0.9889 - val_accuracy: 0.9612\n",
      "Epoch 498/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.0282e-05 - accuracy: 1.0000 - val_loss: 1.0078 - val_accuracy: 0.9636\n",
      "Epoch 499/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.9950 - val_accuracy: 0.9612\n",
      "Epoch 500/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 1.0021 - val_accuracy: 0.9636\n",
      "Epoch 501/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.9214e-09 - accuracy: 1.0000 - val_loss: 1.0024 - val_accuracy: 0.9636\n",
      "Epoch 502/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.9469 - val_accuracy: 0.9600\n",
      "Epoch 503/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3832e-08 - accuracy: 1.0000 - val_loss: 0.9470 - val_accuracy: 0.9600\n",
      "Epoch 504/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.0149e-07 - accuracy: 1.0000 - val_loss: 0.9985 - val_accuracy: 0.9624\n",
      "Epoch 505/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.0639e-09 - accuracy: 1.0000 - val_loss: 0.9991 - val_accuracy: 0.9624\n",
      "Epoch 506/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.8409e-09 - accuracy: 1.0000 - val_loss: 1.0032 - val_accuracy: 0.9624\n",
      "Epoch 507/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 2.1542e-07 - accuracy: 1.0000 - val_loss: 0.9714 - val_accuracy: 0.9612\n",
      "Epoch 508/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.0048 - val_accuracy: 0.9624\n",
      "Epoch 509/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.1888e-08 - accuracy: 1.0000 - val_loss: 1.0062 - val_accuracy: 0.9624\n",
      "Epoch 510/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 3.4722e-08 - accuracy: 1.0000 - val_loss: 1.0074 - val_accuracy: 0.9624\n",
      "Epoch 511/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 9.9167e-08 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.9624\n",
      "Epoch 512/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 4.0092e-07 - accuracy: 1.0000 - val_loss: 0.9686 - val_accuracy: 0.9612\n",
      "Epoch 513/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 0.9693 - val_accuracy: 0.9612\n",
      "Epoch 514/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 6.8445e-09 - accuracy: 1.0000 - val_loss: 0.9713 - val_accuracy: 0.9612\n",
      "Epoch 515/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 0.9731 - val_accuracy: 0.9612\n",
      "Epoch 516/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 0.9748 - val_accuracy: 0.9612\n",
      "Epoch 517/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.9945e-09 - accuracy: 1.0000 - val_loss: 0.9782 - val_accuracy: 0.9612\n",
      "Epoch 518/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 0.9612\n",
      "Epoch 519/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 0.9743 - val_accuracy: 0.9612\n",
      "Epoch 520/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.9250e-09 - accuracy: 1.0000 - val_loss: 0.9757 - val_accuracy: 0.9612\n",
      "Epoch 521/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.3528e-09 - accuracy: 1.0000 - val_loss: 0.9768 - val_accuracy: 0.9612\n",
      "Epoch 522/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 0.9772 - val_accuracy: 0.9612\n",
      "Epoch 523/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 3.3937e-08 - accuracy: 1.0000 - val_loss: 0.9902 - val_accuracy: 0.9612\n",
      "Epoch 524/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 0.9907 - val_accuracy: 0.9612\n",
      "Epoch 525/1000\n",
      "53/53 [==============================] - 3s 47ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 1.0081 - val_accuracy: 0.9612\n",
      "Epoch 526/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 0.9984 - val_accuracy: 0.9600\n",
      "Epoch 527/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 4.2848e-08 - accuracy: 1.0000 - val_loss: 0.9895 - val_accuracy: 0.9612\n",
      "Epoch 528/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 6.2741e-09 - accuracy: 1.0000 - val_loss: 0.9792 - val_accuracy: 0.9600\n",
      "Epoch 529/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 1.2049e-08 - accuracy: 1.0000 - val_loss: 1.0023 - val_accuracy: 0.9612\n",
      "Epoch 530/1000\n",
      "53/53 [==============================] - 2s 41ms/step - loss: 3.8501e-09 - accuracy: 1.0000 - val_loss: 1.0044 - val_accuracy: 0.9612\n",
      "Epoch 531/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 1.0025 - val_accuracy: 0.9612\n",
      "Epoch 532/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 1.0033 - val_accuracy: 0.9612\n",
      "Epoch 533/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0061 - val_accuracy: 0.9612\n",
      "Epoch 534/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.9232e-09 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.9612\n",
      "Epoch 535/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 1.0083 - val_accuracy: 0.9612\n",
      "Epoch 536/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 1.0087 - val_accuracy: 0.9612\n",
      "Epoch 537/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0090 - val_accuracy: 0.9612\n",
      "Epoch 538/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0092 - val_accuracy: 0.9612\n",
      "Epoch 539/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5649e-09 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.9612\n",
      "Epoch 540/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 1.0277 - val_accuracy: 0.9636\n",
      "Epoch 541/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 3.2084e-09 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.9636\n",
      "Epoch 542/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.9636\n",
      "Epoch 543/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0278 - val_accuracy: 0.9636\n",
      "Epoch 544/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.2536e-06 - accuracy: 1.0000 - val_loss: 1.0029 - val_accuracy: 0.9612\n",
      "Epoch 545/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 1.0037 - val_accuracy: 0.9612\n",
      "Epoch 546/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 3.2797e-09 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.9612\n",
      "Epoch 547/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0219 - val_accuracy: 0.9624\n",
      "Epoch 548/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.2958e-08 - accuracy: 1.0000 - val_loss: 1.0231 - val_accuracy: 0.9624\n",
      "Epoch 549/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 1.0237 - val_accuracy: 0.9624\n",
      "Epoch 550/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.9624\n",
      "Epoch 551/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 5.9890e-09 - accuracy: 1.0000 - val_loss: 1.0242 - val_accuracy: 0.9624\n",
      "Epoch 552/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.9624\n",
      "Epoch 553/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5614e-08 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 0.9612\n",
      "Epoch 554/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.9612\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 26ms/step - loss: 3.3510e-09 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9600\n",
      "Epoch 556/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.2797e-09 - accuracy: 1.0000 - val_loss: 1.0101 - val_accuracy: 0.9612\n",
      "Epoch 557/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.9612\n",
      "Epoch 558/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.0639e-09 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.9612\n",
      "Epoch 559/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0126 - val_accuracy: 0.9612\n",
      "Epoch 560/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.9612\n",
      "Epoch 561/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.1279e-09 - accuracy: 1.0000 - val_loss: 1.0171 - val_accuracy: 0.9612\n",
      "Epoch 562/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 1.0182 - val_accuracy: 0.9612\n",
      "Epoch 563/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.9612\n",
      "Epoch 564/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.9612\n",
      "Epoch 565/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.9612\n",
      "Epoch 566/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.9612\n",
      "Epoch 567/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.0658e-09 - accuracy: 1.0000 - val_loss: 1.0120 - val_accuracy: 0.9612\n",
      "Epoch 568/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 1.0558 - val_accuracy: 0.9636\n",
      "Epoch 569/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.7019e-09 - accuracy: 1.0000 - val_loss: 1.0562 - val_accuracy: 0.9636\n",
      "Epoch 570/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-09 - accuracy: 1.0000 - val_loss: 1.0559 - val_accuracy: 0.9636\n",
      "Epoch 571/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 1.0561 - val_accuracy: 0.9636\n",
      "Epoch 572/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4735e-08 - accuracy: 1.0000 - val_loss: 1.0308 - val_accuracy: 0.9612\n",
      "Epoch 573/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.9612\n",
      "Epoch 574/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.9612\n",
      "Epoch 575/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.7806e-09 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.9612\n",
      "Epoch 576/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0305 - val_accuracy: 0.9612\n",
      "Epoch 577/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0093 - accuracy: 0.9994 - val_loss: 1.0148 - val_accuracy: 0.9600\n",
      "Epoch 578/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.4186e-09 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.9600\n",
      "Epoch 579/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.9600\n",
      "Epoch 580/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.1903e-08 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 0.9600\n",
      "Epoch 581/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0170 - val_accuracy: 0.9600\n",
      "Epoch 582/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.7093e-09 - accuracy: 1.0000 - val_loss: 1.0186 - val_accuracy: 0.9600\n",
      "Epoch 583/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4241e-09 - accuracy: 1.0000 - val_loss: 1.0177 - val_accuracy: 0.9612\n",
      "Epoch 584/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 0.0124 - accuracy: 0.9994 - val_loss: 1.0277 - val_accuracy: 0.9624\n",
      "Epoch 585/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.9624\n",
      "Epoch 586/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0277 - val_accuracy: 0.9624\n",
      "Epoch 587/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.2797e-09 - accuracy: 1.0000 - val_loss: 1.0279 - val_accuracy: 0.9624\n",
      "Epoch 588/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0273 - val_accuracy: 0.9624\n",
      "Epoch 589/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0271 - val_accuracy: 0.9624\n",
      "Epoch 590/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0270 - val_accuracy: 0.9624\n",
      "Epoch 591/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0265 - val_accuracy: 0.9624\n",
      "Epoch 592/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.9624\n",
      "Epoch 593/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.9624\n",
      "Epoch 594/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0253 - val_accuracy: 0.9624\n",
      "Epoch 595/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0251 - val_accuracy: 0.9624\n",
      "Epoch 596/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9624\n",
      "Epoch 597/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 1.0370 - val_accuracy: 0.9624\n",
      "Epoch 598/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.4241e-09 - accuracy: 1.0000 - val_loss: 1.0368 - val_accuracy: 0.9624\n",
      "Epoch 599/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 2.1389e-09 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.9624\n",
      "Epoch 600/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0369 - val_accuracy: 0.9624\n",
      "Epoch 601/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 4.7769e-09 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 0.9624\n",
      "Epoch 602/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.9179e-08 - accuracy: 1.0000 - val_loss: 0.9945 - val_accuracy: 0.9612\n",
      "Epoch 603/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 0.9951 - val_accuracy: 0.9612\n",
      "Epoch 604/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.2084e-09 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 0.9612\n",
      "Epoch 605/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 3.6362e-09 - accuracy: 1.0000 - val_loss: 1.0243 - val_accuracy: 0.9624\n",
      "Epoch 606/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.9624\n",
      "Epoch 607/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.9624\n",
      "Epoch 608/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0311 - val_accuracy: 0.9624\n",
      "Epoch 609/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.1555e-07 - accuracy: 1.0000 - val_loss: 1.0325 - val_accuracy: 0.9624\n",
      "Epoch 610/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.9624\n",
      "Epoch 611/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0283 - val_accuracy: 0.9624\n",
      "Epoch 612/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 1.0202 - val_accuracy: 0.9612\n",
      "Epoch 613/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 0.9624\n",
      "Epoch 614/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.9624\n",
      "Epoch 615/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0288 - val_accuracy: 0.9624\n",
      "Epoch 616/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 1.0417 - val_accuracy: 0.9636\n",
      "Epoch 617/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0140 - accuracy: 0.9994 - val_loss: 1.0260 - val_accuracy: 0.9636\n",
      "Epoch 618/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 1.0259 - val_accuracy: 0.9636\n",
      "Epoch 619/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.9333 - val_accuracy: 0.9600\n",
      "Epoch 620/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9333 - val_accuracy: 0.9600\n",
      "Epoch 621/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 0.9335 - val_accuracy: 0.9600\n",
      "Epoch 622/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 0.9336 - val_accuracy: 0.9600\n",
      "Epoch 623/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.7732e-09 - accuracy: 1.0000 - val_loss: 0.9345 - val_accuracy: 0.9600\n",
      "Epoch 624/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 0.9352 - val_accuracy: 0.9600\n",
      "Epoch 625/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.4612e-08 - accuracy: 1.0000 - val_loss: 1.0217 - val_accuracy: 0.9636\n",
      "Epoch 626/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.4149e-09 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.9624\n",
      "Epoch 627/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.0621e-09 - accuracy: 1.0000 - val_loss: 0.9754 - val_accuracy: 0.9612\n",
      "Epoch 628/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.9612\n",
      "Epoch 629/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9764 - val_accuracy: 0.9612\n",
      "Epoch 630/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.3473e-09 - accuracy: 1.0000 - val_loss: 0.9672 - val_accuracy: 0.9612\n",
      "Epoch 631/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4402e-08 - accuracy: 1.0000 - val_loss: 0.9502 - val_accuracy: 0.9624\n",
      "Epoch 632/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.3303e-07 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.9636\n",
      "Epoch 633/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0325 - val_accuracy: 0.9636\n",
      "Epoch 634/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0326 - val_accuracy: 0.9636\n",
      "Epoch 635/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0310 - val_accuracy: 0.9636\n",
      "Epoch 636/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.6569e-07 - accuracy: 1.0000 - val_loss: 0.9978 - val_accuracy: 0.9624\n",
      "Epoch 637/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1550e-08 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.9624\n",
      "Epoch 638/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.9624\n",
      "Epoch 639/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 1.0021 - val_accuracy: 0.9624\n",
      "Epoch 640/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0026 - val_accuracy: 0.9624\n",
      "Epoch 641/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0007 - val_accuracy: 0.9624\n",
      "Epoch 642/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 0.9624\n",
      "Epoch 643/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 4.1352e-09 - accuracy: 1.0000 - val_loss: 1.0002 - val_accuracy: 0.9612\n",
      "Epoch 644/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0000 - val_accuracy: 0.9612\n",
      "Epoch 645/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9996 - val_accuracy: 0.9612\n",
      "Epoch 646/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.9612\n",
      "Epoch 647/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 0.9981 - val_accuracy: 0.9612\n",
      "Epoch 648/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 0.9979 - val_accuracy: 0.9612\n",
      "Epoch 649/1000\n",
      "53/53 [==============================] - 2s 46ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 0.9975 - val_accuracy: 0.9612\n",
      "Epoch 650/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 0.9968 - val_accuracy: 0.9612\n",
      "Epoch 651/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0131 - accuracy: 0.9982 - val_loss: 1.0159 - val_accuracy: 0.9636\n",
      "Epoch 652/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.9103e-08 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.9636\n",
      "Epoch 653/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.8519e-09 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.9636\n",
      "Epoch 654/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 2.9232e-09 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.9636\n",
      "Epoch 655/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.9703e-07 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.9636\n",
      "Epoch 656/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 1.0254 - val_accuracy: 0.9636\n",
      "Epoch 657/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 1.0188 - val_accuracy: 0.9624\n",
      "Epoch 658/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0189 - val_accuracy: 0.9624\n",
      "Epoch 659/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 8.4131e-09 - accuracy: 1.0000 - val_loss: 0.9885 - val_accuracy: 0.9612\n",
      "Epoch 660/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 4.0639e-09 - accuracy: 1.0000 - val_loss: 0.9867 - val_accuracy: 0.9612\n",
      "Epoch 661/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 1.6775e-07 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.9636\n",
      "Epoch 662/1000\n",
      "53/53 [==============================] - 3s 50ms/step - loss: 6.1316e-09 - accuracy: 1.0000 - val_loss: 1.0412 - val_accuracy: 0.9636\n",
      "Epoch 663/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 2.4241e-09 - accuracy: 1.0000 - val_loss: 1.0151 - val_accuracy: 0.9612\n",
      "Epoch 664/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 2.9232e-09 - accuracy: 1.0000 - val_loss: 1.0159 - val_accuracy: 0.9612\n",
      "Epoch 665/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 32ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0158 - val_accuracy: 0.9612\n",
      "Epoch 666/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.9612\n",
      "Epoch 667/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 1.0084 - val_accuracy: 0.9612\n",
      "Epoch 668/1000\n",
      "53/53 [==============================] - 2s 46ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.9612\n",
      "Epoch 669/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 6.1316e-09 - accuracy: 1.0000 - val_loss: 0.9992 - val_accuracy: 0.9612\n",
      "Epoch 670/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 1.9250e-09 - accuracy: 1.0000 - val_loss: 1.0153 - val_accuracy: 0.9612\n",
      "Epoch 671/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.9119 - val_accuracy: 0.9648\n",
      "Epoch 672/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 0.0151 - accuracy: 0.9982 - val_loss: 0.9555 - val_accuracy: 0.9624\n",
      "Epoch 673/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 3.0658e-09 - accuracy: 1.0000 - val_loss: 0.9554 - val_accuracy: 0.9624\n",
      "Epoch 674/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.5485e-06 - accuracy: 1.0000 - val_loss: 0.9478 - val_accuracy: 0.9624\n",
      "Epoch 675/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.9393 - val_accuracy: 0.9624\n",
      "Epoch 676/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 2.3528e-09 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.9624\n",
      "Epoch 677/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 3.3510e-09 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.9624\n",
      "Epoch 678/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5869e-07 - accuracy: 1.0000 - val_loss: 0.9391 - val_accuracy: 0.9624\n",
      "Epoch 679/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 0.9387 - val_accuracy: 0.9624\n",
      "Epoch 680/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 0.9375 - val_accuracy: 0.9624\n",
      "Epoch 681/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 1.7773e-07 - accuracy: 1.0000 - val_loss: 0.9914 - val_accuracy: 0.9624\n",
      "Epoch 682/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 4.7769e-09 - accuracy: 1.0000 - val_loss: 0.9829 - val_accuracy: 0.9624\n",
      "Epoch 683/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.9958 - val_accuracy: 0.9624\n",
      "Epoch 684/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.5667e-09 - accuracy: 1.0000 - val_loss: 0.9961 - val_accuracy: 0.9624\n",
      "Epoch 685/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 0.9962 - val_accuracy: 0.9624\n",
      "Epoch 686/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 0.9963 - val_accuracy: 0.9624\n",
      "Epoch 687/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 1.2334e-08 - accuracy: 1.0000 - val_loss: 0.9834 - val_accuracy: 0.9624\n",
      "Epoch 688/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 2.9945e-09 - accuracy: 1.0000 - val_loss: 0.9783 - val_accuracy: 0.9624\n",
      "Epoch 689/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 2.9232e-09 - accuracy: 1.0000 - val_loss: 0.9814 - val_accuracy: 0.9624\n",
      "Epoch 690/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 0.9762 - val_accuracy: 0.9624\n",
      "Epoch 691/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.9624\n",
      "Epoch 692/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 0.9773 - val_accuracy: 0.9624\n",
      "Epoch 693/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 0.9612\n",
      "Epoch 694/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 0.9759 - val_accuracy: 0.9612\n",
      "Epoch 695/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 0.0017 - accuracy: 0.9994 - val_loss: 1.0008 - val_accuracy: 0.9624\n",
      "Epoch 696/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 8.4844e-09 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.9624\n",
      "Epoch 697/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0006 - val_accuracy: 0.9624\n",
      "Epoch 698/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 7.2819e-04 - accuracy: 0.9994 - val_loss: 1.0131 - val_accuracy: 0.9624\n",
      "Epoch 699/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 2.3528e-09 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.9624\n",
      "Epoch 700/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0132 - val_accuracy: 0.9624\n",
      "Epoch 701/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 6.6306e-09 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 0.9624\n",
      "Epoch 702/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9624\n",
      "Epoch 703/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 2.2102e-09 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9624\n",
      "Epoch 704/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.9624\n",
      "Epoch 705/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.9624\n",
      "Epoch 706/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 4.4275e-08 - accuracy: 1.0000 - val_loss: 1.0360 - val_accuracy: 0.9624\n",
      "Epoch 707/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0353 - val_accuracy: 0.9624\n",
      "Epoch 708/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 1.0367 - val_accuracy: 0.9624\n",
      "Epoch 709/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 3.9214e-09 - accuracy: 1.0000 - val_loss: 1.0324 - val_accuracy: 0.9624\n",
      "Epoch 710/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0312 - val_accuracy: 0.9624\n",
      "Epoch 711/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 1.0302 - val_accuracy: 0.9624\n",
      "Epoch 712/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0306 - val_accuracy: 0.9624\n",
      "Epoch 713/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 1.0284 - val_accuracy: 0.9624\n",
      "Epoch 714/1000\n",
      "53/53 [==============================] - 1s 21ms/step - loss: 7.7714e-09 - accuracy: 1.0000 - val_loss: 1.0309 - val_accuracy: 0.9624\n",
      "Epoch 715/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 1.0313 - val_accuracy: 0.9624\n",
      "Epoch 716/1000\n",
      "53/53 [==============================] - 1s 22ms/step - loss: 5.8464e-09 - accuracy: 1.0000 - val_loss: 1.0123 - val_accuracy: 0.9612\n",
      "Epoch 717/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.9612\n",
      "Epoch 718/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.6362e-09 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9612\n",
      "Epoch 719/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 3.2797e-09 - accuracy: 1.0000 - val_loss: 1.0105 - val_accuracy: 0.9612\n",
      "Epoch 720/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.9612\n",
      "Epoch 721/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 5.0621e-09 - accuracy: 1.0000 - val_loss: 1.0134 - val_accuracy: 0.9612\n",
      "Epoch 722/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0139 - val_accuracy: 0.9612\n",
      "Epoch 723/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9612\n",
      "Epoch 724/1000\n",
      "53/53 [==============================] - 2s 27ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 1.0179 - val_accuracy: 0.9612\n",
      "Epoch 725/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.2834e-09 - accuracy: 1.0000 - val_loss: 1.0145 - val_accuracy: 0.9612\n",
      "Epoch 726/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 1.0289 - val_accuracy: 0.9624\n",
      "Epoch 727/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 3.8501e-09 - accuracy: 1.0000 - val_loss: 1.0030 - val_accuracy: 0.9600\n",
      "Epoch 728/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 3.9213e-09 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.9612\n",
      "Epoch 729/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0299 - val_accuracy: 0.9612\n",
      "Epoch 730/1000\n",
      "53/53 [==============================] - 2s 28ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 0.9612\n",
      "Epoch 731/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 5.0621e-09 - accuracy: 1.0000 - val_loss: 1.0670 - val_accuracy: 0.9624\n",
      "Epoch 732/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0679 - val_accuracy: 0.9624\n",
      "Epoch 733/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 1.0409e-08 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.9624\n",
      "Epoch 734/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0600 - val_accuracy: 0.9624\n",
      "Epoch 735/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.0658e-09 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.9624\n",
      "Epoch 736/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.9612\n",
      "Epoch 737/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0441 - val_accuracy: 0.9612\n",
      "Epoch 738/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0444 - val_accuracy: 0.9612\n",
      "Epoch 739/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0446 - val_accuracy: 0.9612\n",
      "Epoch 740/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0452 - val_accuracy: 0.9612\n",
      "Epoch 741/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.9612\n",
      "Epoch 742/1000\n",
      "53/53 [==============================] - 2s 38ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.9612\n",
      "Epoch 743/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.9612\n",
      "Epoch 744/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-09 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.9612\n",
      "Epoch 745/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0414 - val_accuracy: 0.9612\n",
      "Epoch 746/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0398 - val_accuracy: 0.9612\n",
      "Epoch 747/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4968e-04 - accuracy: 1.0000 - val_loss: 1.0669 - val_accuracy: 0.9636\n",
      "Epoch 748/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.6113e-08 - accuracy: 1.0000 - val_loss: 1.0673 - val_accuracy: 0.9636\n",
      "Epoch 749/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.7488e-05 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.9636\n",
      "Epoch 750/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0218 - val_accuracy: 0.9636\n",
      "Epoch 751/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.6325e-09 - accuracy: 1.0000 - val_loss: 1.0224 - val_accuracy: 0.9636\n",
      "Epoch 752/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.9636\n",
      "Epoch 753/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0225 - val_accuracy: 0.9636\n",
      "Epoch 754/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0227 - val_accuracy: 0.9636\n",
      "Epoch 755/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0230 - val_accuracy: 0.9636\n",
      "Epoch 756/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.0382e-07 - accuracy: 1.0000 - val_loss: 1.0902 - val_accuracy: 0.9624\n",
      "Epoch 757/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-09 - accuracy: 1.0000 - val_loss: 1.0907 - val_accuracy: 0.9624\n",
      "Epoch 758/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0911 - val_accuracy: 0.9624\n",
      "Epoch 759/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0913 - val_accuracy: 0.9624\n",
      "Epoch 760/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.4223e-09 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9624\n",
      "Epoch 761/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.9624\n",
      "Epoch 762/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0807 - val_accuracy: 0.9624\n",
      "Epoch 763/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.0795 - val_accuracy: 0.9624\n",
      "Epoch 764/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0799 - val_accuracy: 0.9624\n",
      "Epoch 765/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5649e-09 - accuracy: 1.0000 - val_loss: 1.0815 - val_accuracy: 0.9624\n",
      "Epoch 766/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0819 - val_accuracy: 0.9624\n",
      "Epoch 767/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 1.0835 - val_accuracy: 0.9624\n",
      "Epoch 768/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0816 - val_accuracy: 0.9612\n",
      "Epoch 769/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0821 - val_accuracy: 0.9612\n",
      "Epoch 770/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 1.0748 - val_accuracy: 0.9612\n",
      "Epoch 771/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0751 - val_accuracy: 0.9612\n",
      "Epoch 772/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 1.0761 - val_accuracy: 0.9612\n",
      "Epoch 773/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0464 - val_accuracy: 0.9612\n",
      "Epoch 774/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0465 - val_accuracy: 0.9612\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 24ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0468 - val_accuracy: 0.9612\n",
      "Epoch 776/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 1.0474 - val_accuracy: 0.9612\n",
      "Epoch 777/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 1.0476 - val_accuracy: 0.9624\n",
      "Epoch 778/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 1.0492 - val_accuracy: 0.9612\n",
      "Epoch 779/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0493 - val_accuracy: 0.9612\n",
      "Epoch 780/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.7824e-09 - accuracy: 1.0000 - val_loss: 1.0494 - val_accuracy: 0.9612\n",
      "Epoch 781/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.9250e-09 - accuracy: 1.0000 - val_loss: 1.0501 - val_accuracy: 0.9612\n",
      "Epoch 782/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0501 - val_accuracy: 0.9612\n",
      "Epoch 783/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0504 - val_accuracy: 0.9612\n",
      "Epoch 784/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0511 - val_accuracy: 0.9612\n",
      "Epoch 785/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0513 - val_accuracy: 0.9612\n",
      "Epoch 786/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 1.0524 - val_accuracy: 0.9612\n",
      "Epoch 787/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.5593e-09 - accuracy: 1.0000 - val_loss: 1.0543 - val_accuracy: 0.9612\n",
      "Epoch 788/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.9612\n",
      "Epoch 789/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0550 - val_accuracy: 0.9612\n",
      "Epoch 790/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0551 - val_accuracy: 0.9612\n",
      "Epoch 791/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0558 - val_accuracy: 0.9612\n",
      "Epoch 792/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.0564 - val_accuracy: 0.9612\n",
      "Epoch 793/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 1.0573 - val_accuracy: 0.9612\n",
      "Epoch 794/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.9612\n",
      "Epoch 795/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0577 - val_accuracy: 0.9612\n",
      "Epoch 796/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0583 - val_accuracy: 0.9624\n",
      "Epoch 797/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0587 - val_accuracy: 0.9624\n",
      "Epoch 798/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.7587e-06 - accuracy: 1.0000 - val_loss: 1.1045 - val_accuracy: 0.9636\n",
      "Epoch 799/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 1.0677 - val_accuracy: 0.9612\n",
      "Epoch 800/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0189 - accuracy: 0.9988 - val_loss: 1.1005 - val_accuracy: 0.9624\n",
      "Epoch 801/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.9624\n",
      "Epoch 802/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.9624\n",
      "Epoch 803/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 1.1005 - val_accuracy: 0.9624\n",
      "Epoch 804/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.1279e-09 - accuracy: 1.0000 - val_loss: 1.1016 - val_accuracy: 0.9624\n",
      "Epoch 805/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.4954e-09 - accuracy: 1.0000 - val_loss: 1.0996 - val_accuracy: 0.9624\n",
      "Epoch 806/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.9624\n",
      "Epoch 807/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0896 - val_accuracy: 0.9624\n",
      "Epoch 808/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.2065e-09 - accuracy: 1.0000 - val_loss: 1.0767 - val_accuracy: 0.9612\n",
      "Epoch 809/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 0.9612\n",
      "Epoch 810/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2065e-09 - accuracy: 1.0000 - val_loss: 1.0800 - val_accuracy: 0.9612\n",
      "Epoch 811/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0798 - val_accuracy: 0.9612\n",
      "Epoch 812/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0801 - val_accuracy: 0.9612\n",
      "Epoch 813/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0802 - val_accuracy: 0.9612\n",
      "Epoch 814/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0776 - val_accuracy: 0.9612\n",
      "Epoch 815/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 1.0747 - val_accuracy: 0.9612\n",
      "Epoch 816/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0753 - val_accuracy: 0.9612\n",
      "Epoch 817/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.1334e-09 - accuracy: 1.0000 - val_loss: 1.0683 - val_accuracy: 0.9612\n",
      "Epoch 818/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0693 - val_accuracy: 0.9612\n",
      "Epoch 819/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0689 - val_accuracy: 0.9612\n",
      "Epoch 820/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.9612\n",
      "Epoch 821/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0655 - val_accuracy: 0.9612\n",
      "Epoch 822/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0657 - val_accuracy: 0.9612\n",
      "Epoch 823/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 1.0626 - val_accuracy: 0.9612\n",
      "Epoch 824/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0624 - val_accuracy: 0.9612\n",
      "Epoch 825/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.7378e-08 - accuracy: 1.0000 - val_loss: 1.0603 - val_accuracy: 0.9612\n",
      "Epoch 826/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0607 - val_accuracy: 0.9612\n",
      "Epoch 827/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.4241e-09 - accuracy: 1.0000 - val_loss: 1.0644 - val_accuracy: 0.9612\n",
      "Epoch 828/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0069 - accuracy: 0.9994 - val_loss: 1.0343 - val_accuracy: 0.9624\n",
      "Epoch 829/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.7914e-07 - accuracy: 1.0000 - val_loss: 1.0383 - val_accuracy: 0.9600\n",
      "Epoch 830/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 4.3846e-08 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.9600\n",
      "Epoch 831/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 0.9600\n",
      "Epoch 832/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.7499e-05 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.9600\n",
      "Epoch 833/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3547e-09 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.9600\n",
      "Epoch 834/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0622 - val_accuracy: 0.9600\n",
      "Epoch 835/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.0577e-06 - accuracy: 1.0000 - val_loss: 1.1097 - val_accuracy: 0.9624\n",
      "Epoch 836/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.9624\n",
      "Epoch 837/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.5310e-08 - accuracy: 1.0000 - val_loss: 1.0780 - val_accuracy: 0.9612\n",
      "Epoch 838/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0782 - val_accuracy: 0.9612\n",
      "Epoch 839/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0786 - val_accuracy: 0.9612\n",
      "Epoch 840/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9612\n",
      "Epoch 841/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.4241e-09 - accuracy: 1.0000 - val_loss: 1.0779 - val_accuracy: 0.9600\n",
      "Epoch 842/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.4578e-08 - accuracy: 1.0000 - val_loss: 1.0565 - val_accuracy: 0.9624\n",
      "Epoch 843/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.5685e-09 - accuracy: 1.0000 - val_loss: 1.0759 - val_accuracy: 0.9600\n",
      "Epoch 844/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0759 - val_accuracy: 0.9600\n",
      "Epoch 845/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.0597e-04 - accuracy: 1.0000 - val_loss: 1.1173 - val_accuracy: 0.9624\n",
      "Epoch 846/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.1173 - val_accuracy: 0.9624\n",
      "Epoch 847/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.1174 - val_accuracy: 0.9624\n",
      "Epoch 848/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.9624\n",
      "Epoch 849/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3546e-09 - accuracy: 1.0000 - val_loss: 1.1182 - val_accuracy: 0.9624\n",
      "Epoch 850/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0146 - accuracy: 0.9994 - val_loss: 1.0603 - val_accuracy: 0.9612\n",
      "Epoch 851/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.5182e-05 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.9624\n",
      "Epoch 852/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0979 - val_accuracy: 0.9624\n",
      "Epoch 853/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.2263e-08 - accuracy: 1.0000 - val_loss: 1.1056 - val_accuracy: 0.9624\n",
      "Epoch 854/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.8390e-09 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.9624\n",
      "Epoch 855/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.9624\n",
      "Epoch 856/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 0.9624\n",
      "Epoch 857/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.1093 - val_accuracy: 0.9624\n",
      "Epoch 858/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0846 - val_accuracy: 0.9624\n",
      "Epoch 859/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0794 - val_accuracy: 0.9624\n",
      "Epoch 860/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.4507e-08 - accuracy: 1.0000 - val_loss: 1.0556 - val_accuracy: 0.9600\n",
      "Epoch 861/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0555 - val_accuracy: 0.9600\n",
      "Epoch 862/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.0676e-09 - accuracy: 1.0000 - val_loss: 1.0728 - val_accuracy: 0.9600\n",
      "Epoch 863/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 1.1027 - val_accuracy: 0.9636\n",
      "Epoch 864/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.6362e-09 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.9624\n",
      "Epoch 865/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.9624\n",
      "Epoch 866/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1027 - val_accuracy: 0.9624\n",
      "Epoch 867/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 1.1046 - val_accuracy: 0.9624\n",
      "Epoch 868/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.1756e-07 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 0.9600\n",
      "Epoch 869/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.7430e-08 - accuracy: 1.0000 - val_loss: 1.1239 - val_accuracy: 0.9624\n",
      "Epoch 870/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.0081e-07 - accuracy: 1.0000 - val_loss: 1.1017 - val_accuracy: 0.9600\n",
      "Epoch 871/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.1155e-07 - accuracy: 1.0000 - val_loss: 1.1367 - val_accuracy: 0.9624\n",
      "Epoch 872/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.1368 - val_accuracy: 0.9624\n",
      "Epoch 873/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.9624\n",
      "Epoch 874/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.9624\n",
      "Epoch 875/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.5667e-09 - accuracy: 1.0000 - val_loss: 1.1396 - val_accuracy: 0.9624\n",
      "Epoch 876/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 6.5593e-09 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.9624\n",
      "Epoch 877/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.9624\n",
      "Epoch 878/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1378 - val_accuracy: 0.9624\n",
      "Epoch 879/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.1380 - val_accuracy: 0.9624\n",
      "Epoch 880/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1381 - val_accuracy: 0.9624\n",
      "Epoch 881/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-09 - accuracy: 1.0000 - val_loss: 1.1369 - val_accuracy: 0.9624\n",
      "Epoch 882/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.1372 - val_accuracy: 0.9624\n",
      "Epoch 883/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.1371 - val_accuracy: 0.9624\n",
      "Epoch 884/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.9624\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 1s 26ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.9624\n",
      "Epoch 886/1000\n",
      "53/53 [==============================] - 2s 30ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1376 - val_accuracy: 0.9624\n",
      "Epoch 887/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1374 - val_accuracy: 0.9624\n",
      "Epoch 888/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.1365 - val_accuracy: 0.9624\n",
      "Epoch 889/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1283 - val_accuracy: 0.9624\n",
      "Epoch 890/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.1268 - val_accuracy: 0.9624\n",
      "Epoch 891/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.9624\n",
      "Epoch 892/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.9624\n",
      "Epoch 893/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.9624\n",
      "Epoch 894/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1272 - val_accuracy: 0.9624\n",
      "Epoch 895/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1268 - val_accuracy: 0.9624\n",
      "Epoch 896/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.1269 - val_accuracy: 0.9624\n",
      "Epoch 897/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 4.9908e-09 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.9612\n",
      "Epoch 898/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.9612\n",
      "Epoch 899/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1083 - val_accuracy: 0.9612\n",
      "Epoch 900/1000\n",
      "53/53 [==============================] - 1s 26ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.9612\n",
      "Epoch 901/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.1052 - val_accuracy: 0.9612\n",
      "Epoch 902/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1038 - val_accuracy: 0.9612\n",
      "Epoch 903/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.9612\n",
      "Epoch 904/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1034 - val_accuracy: 0.9612\n",
      "Epoch 905/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1026 - val_accuracy: 0.9612\n",
      "Epoch 906/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1835e-08 - accuracy: 1.0000 - val_loss: 1.0887 - val_accuracy: 0.9612\n",
      "Epoch 907/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 1.0885 - val_accuracy: 0.9612\n",
      "Epoch 908/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.8427e-10 - accuracy: 1.0000 - val_loss: 1.0881 - val_accuracy: 0.9612\n",
      "Epoch 909/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0883 - val_accuracy: 0.9612\n",
      "Epoch 910/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0884 - val_accuracy: 0.9612\n",
      "Epoch 911/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.6398e-09 - accuracy: 1.0000 - val_loss: 1.0863 - val_accuracy: 0.9612\n",
      "Epoch 912/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0867 - val_accuracy: 0.9612\n",
      "Epoch 913/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0861 - val_accuracy: 0.9612\n",
      "Epoch 914/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.9624\n",
      "Epoch 915/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.1297e-10 - accuracy: 1.0000 - val_loss: 1.0845 - val_accuracy: 0.9624\n",
      "Epoch 916/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 0.9624\n",
      "Epoch 917/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0820 - val_accuracy: 0.9624\n",
      "Epoch 918/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 0.9624\n",
      "Epoch 919/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 2.1674e-08 - accuracy: 1.0000 - val_loss: 1.0810 - val_accuracy: 0.9612\n",
      "Epoch 920/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.1219 - val_accuracy: 0.9624\n",
      "Epoch 921/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1218 - val_accuracy: 0.9624\n",
      "Epoch 922/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.1215 - val_accuracy: 0.9624\n",
      "Epoch 923/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1217 - val_accuracy: 0.9624\n",
      "Epoch 924/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 1.1225 - val_accuracy: 0.9624\n",
      "Epoch 925/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.0603e-09 - accuracy: 1.0000 - val_loss: 1.1252 - val_accuracy: 0.9624\n",
      "Epoch 926/1000\n",
      "53/53 [==============================] - 2s 33ms/step - loss: 1.5156e-07 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.9612\n",
      "Epoch 927/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.4259e-10 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.9612\n",
      "Epoch 928/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 9.9816e-10 - accuracy: 1.0000 - val_loss: 1.0916 - val_accuracy: 0.9624\n",
      "Epoch 929/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 4.2778e-10 - accuracy: 1.0000 - val_loss: 1.0919 - val_accuracy: 0.9624\n",
      "Epoch 930/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0921 - val_accuracy: 0.9624\n",
      "Epoch 931/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.9624\n",
      "Epoch 932/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0924 - val_accuracy: 0.9624\n",
      "Epoch 933/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.9624\n",
      "Epoch 934/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.1408e-09 - accuracy: 1.0000 - val_loss: 1.0931 - val_accuracy: 0.9624\n",
      "Epoch 935/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.9624\n",
      "Epoch 936/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0053 - accuracy: 0.9994 - val_loss: 1.0925 - val_accuracy: 0.9612\n",
      "Epoch 937/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 8.5557e-10 - accuracy: 1.0000 - val_loss: 1.0926 - val_accuracy: 0.9612\n",
      "Epoch 938/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0927 - val_accuracy: 0.9612\n",
      "Epoch 939/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0928 - val_accuracy: 0.9612\n",
      "Epoch 940/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.9612\n",
      "Epoch 941/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0932 - val_accuracy: 0.9612\n",
      "Epoch 942/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.2121e-09 - accuracy: 1.0000 - val_loss: 1.0940 - val_accuracy: 0.9612\n",
      "Epoch 943/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0135 - accuracy: 0.9988 - val_loss: 1.1054 - val_accuracy: 0.9612\n",
      "Epoch 944/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 3.5649e-10 - accuracy: 1.0000 - val_loss: 1.1054 - val_accuracy: 0.9612\n",
      "Epoch 945/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.9612\n",
      "Epoch 946/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1055 - val_accuracy: 0.9612\n",
      "Epoch 947/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 8.6269e-09 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.9612\n",
      "Epoch 948/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1086 - val_accuracy: 0.9612\n",
      "Epoch 949/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.5667e-09 - accuracy: 1.0000 - val_loss: 1.1090 - val_accuracy: 0.9600\n",
      "Epoch 950/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.1091 - val_accuracy: 0.9600\n",
      "Epoch 951/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.1092 - val_accuracy: 0.9600\n",
      "Epoch 952/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 1.1305 - val_accuracy: 0.9636\n",
      "Epoch 953/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.4972e-09 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.9636\n",
      "Epoch 954/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.1304 - val_accuracy: 0.9636\n",
      "Epoch 955/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 0.0054 - accuracy: 0.9994 - val_loss: 1.0790 - val_accuracy: 0.9600\n",
      "Epoch 956/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 6.2741e-09 - accuracy: 1.0000 - val_loss: 1.0790 - val_accuracy: 0.9600\n",
      "Epoch 957/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 1.1216 - val_accuracy: 0.9636\n",
      "Epoch 958/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 3.1371e-09 - accuracy: 1.0000 - val_loss: 1.1216 - val_accuracy: 0.9636\n",
      "Epoch 959/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 0.0121 - accuracy: 0.9994 - val_loss: 1.0231 - val_accuracy: 0.9612\n",
      "Epoch 960/1000\n",
      "53/53 [==============================] - 2s 36ms/step - loss: 1.1122e-08 - accuracy: 1.0000 - val_loss: 1.0233 - val_accuracy: 0.9612\n",
      "Epoch 961/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 2.0034e-08 - accuracy: 1.0000 - val_loss: 1.0240 - val_accuracy: 0.9600\n",
      "Epoch 962/1000\n",
      "53/53 [==============================] - 1s 28ms/step - loss: 2.1389e-09 - accuracy: 1.0000 - val_loss: 1.0244 - val_accuracy: 0.9600\n",
      "Epoch 963/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 1.0772 - val_accuracy: 0.9636\n",
      "Epoch 964/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.3555e-05 - accuracy: 1.0000 - val_loss: 1.0124 - val_accuracy: 0.9624\n",
      "Epoch 965/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.4149e-09 - accuracy: 1.0000 - val_loss: 1.0125 - val_accuracy: 0.9624\n",
      "Epoch 966/1000\n",
      "53/53 [==============================] - 2s 34ms/step - loss: 1.2426e-07 - accuracy: 1.0000 - val_loss: 1.0285 - val_accuracy: 0.9624\n",
      "Epoch 967/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 0.0066 - accuracy: 0.9994 - val_loss: 0.9833 - val_accuracy: 0.9624\n",
      "Epoch 968/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 1.2406e-08 - accuracy: 1.0000 - val_loss: 0.9832 - val_accuracy: 0.9624\n",
      "Epoch 969/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0888e-05 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.9648\n",
      "Epoch 970/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 5.0595e-05 - accuracy: 1.0000 - val_loss: 1.0160 - val_accuracy: 0.9624\n",
      "Epoch 971/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 1.0202e-07 - accuracy: 1.0000 - val_loss: 1.0542 - val_accuracy: 0.9624\n",
      "Epoch 972/1000\n",
      "53/53 [==============================] - 1s 24ms/step - loss: 6.4881e-09 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 0.9624\n",
      "Epoch 973/1000\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 9.9103e-09 - accuracy: 1.0000 - val_loss: 1.0543 - val_accuracy: 0.9624\n",
      "Epoch 974/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 1.0695e-09 - accuracy: 1.0000 - val_loss: 1.0536 - val_accuracy: 0.9624\n",
      "Epoch 975/1000\n",
      "53/53 [==============================] - 2s 31ms/step - loss: 1.8537e-09 - accuracy: 1.0000 - val_loss: 1.0466 - val_accuracy: 0.9624\n",
      "Epoch 976/1000\n",
      "53/53 [==============================] - 2s 35ms/step - loss: 6.9158e-09 - accuracy: 1.0000 - val_loss: 1.0165 - val_accuracy: 0.9600\n",
      "Epoch 977/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 3.9640e-08 - accuracy: 1.0000 - val_loss: 0.9943 - val_accuracy: 0.9600\n",
      "Epoch 978/1000\n",
      "53/53 [==============================] - 2s 39ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 0.9973 - val_accuracy: 0.9600\n",
      "Epoch 979/1000\n",
      "53/53 [==============================] - 2s 40ms/step - loss: 1.9963e-09 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.9624\n",
      "Epoch 980/1000\n",
      "53/53 [==============================] - 2s 37ms/step - loss: 1.5841e-06 - accuracy: 1.0000 - val_loss: 1.0997 - val_accuracy: 0.9636\n",
      "Epoch 981/1000\n",
      "53/53 [==============================] - 3s 55ms/step - loss: 3.3509e-08 - accuracy: 1.0000 - val_loss: 1.1033 - val_accuracy: 0.9636\n",
      "Epoch 982/1000\n",
      "53/53 [==============================] - 3s 49ms/step - loss: 3.6128e-05 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.9612\n",
      "Epoch 983/1000\n",
      "53/53 [==============================] - 3s 65ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0423 - val_accuracy: 0.9612\n",
      "Epoch 984/1000\n",
      "53/53 [==============================] - 3s 53ms/step - loss: 4.9908e-10 - accuracy: 1.0000 - val_loss: 1.0424 - val_accuracy: 0.9612\n",
      "Epoch 985/1000\n",
      "53/53 [==============================] - 3s 65ms/step - loss: 2.8519e-10 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 0.9612\n",
      "Epoch 986/1000\n",
      "53/53 [==============================] - 3s 52ms/step - loss: 6.4168e-10 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.9612\n",
      "Epoch 987/1000\n",
      "53/53 [==============================] - 2s 43ms/step - loss: 9.2687e-10 - accuracy: 1.0000 - val_loss: 1.0432 - val_accuracy: 0.9612\n",
      "Epoch 988/1000\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 7.1297e-11 - accuracy: 1.0000 - val_loss: 1.0433 - val_accuracy: 0.9612\n",
      "Epoch 989/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0434 - val_accuracy: 0.9624\n",
      "Epoch 990/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0438 - val_accuracy: 0.9612\n",
      "Epoch 991/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 1.7111e-09 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 0.9624\n",
      "Epoch 992/1000\n",
      "53/53 [==============================] - 2s 32ms/step - loss: 5.2047e-09 - accuracy: 1.0000 - val_loss: 1.1245 - val_accuracy: 0.9624\n",
      "Epoch 993/1000\n",
      "53/53 [==============================] - 2s 29ms/step - loss: 3.8501e-09 - accuracy: 1.0000 - val_loss: 1.0601 - val_accuracy: 0.9600\n",
      "Epoch 994/1000\n",
      "53/53 [==============================] - 1s 23ms/step - loss: 2.1389e-10 - accuracy: 1.0000 - val_loss: 1.0604 - val_accuracy: 0.9600\n",
      "Epoch 995/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 2s 34ms/step - loss: 5.7038e-10 - accuracy: 1.0000 - val_loss: 1.0609 - val_accuracy: 0.9600\n",
      "Epoch 996/1000\n",
      "53/53 [==============================] - 2s 42ms/step - loss: 9.1260e-09 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9612\n",
      "Epoch 997/1000\n",
      "53/53 [==============================] - 2s 45ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9612\n",
      "Epoch 998/1000\n",
      "53/53 [==============================] - 2s 44ms/step - loss: 2.8519e-09 - accuracy: 1.0000 - val_loss: 1.0597 - val_accuracy: 0.9612\n",
      "Epoch 999/1000\n",
      "53/53 [==============================] - 3s 66ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.1167 - val_accuracy: 0.9636\n",
      "Epoch 1000/1000\n",
      "53/53 [==============================] - 4s 70ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 1.0778 - val_accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,\n",
    "                     questions_train],\n",
    "                    answers_train, \n",
    "                    batch_size = 32, \n",
    "                    epochs = 1000, validation_data = ([inputs_test,\n",
    "                                                       questions_test],\n",
    "                                                      answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2eba462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Z_chatbot_100_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "df0cb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
    "#We can see that without any training the acc is about 50%, random guessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0cd2f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load a model that we have already trained and saved:\n",
    "model.load_weights('Z_chatbot_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f164c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check out the predictions on the test set:\n",
    "#These are just probabilities for every single word on the vocab\n",
    "pred_results = model.predict(([inputs_test,questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e14ecfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['perfect',\n",
       "  'so',\n",
       "  'i',\n",
       "  'bought',\n",
       "  'first',\n",
       "  'carmex',\n",
       "  'three',\n",
       "  'years',\n",
       "  'ago',\n",
       "  'i',\n",
       "  'think',\n",
       "  'i',\n",
       "  'saw',\n",
       "  'friend',\n",
       "  'i',\n",
       "  'love',\n",
       "  'i',\n",
       "  'use',\n",
       "  'i',\n",
       "  'wake',\n",
       "  'day',\n",
       "  'needed',\n",
       "  'i',\n",
       "  'go',\n",
       "  'bed',\n",
       "  'my',\n",
       "  'lips',\n",
       "  'havent',\n",
       "  'dry',\n",
       "  'three',\n",
       "  'years',\n",
       "  'how',\n",
       "  'amazing',\n",
       "  'isnt',\n",
       "  'i',\n",
       "  'used',\n",
       "  'one',\n",
       "  'jar',\n",
       "  'i',\n",
       "  'halfway',\n",
       "  'second',\n",
       "  'one',\n",
       "  'one',\n",
       "  'half',\n",
       "  'jar',\n",
       "  'three',\n",
       "  'years',\n",
       "  'amazing',\n",
       "  'i',\n",
       "  'also',\n",
       "  'got',\n",
       "  'cherry',\n",
       "  'one',\n",
       "  'recently',\n",
       "  'i',\n",
       "  'love',\n",
       "  'scent',\n",
       "  'ah',\n",
       "  'product',\n",
       "  'perfect',\n",
       "  'i',\n",
       "  'really',\n",
       "  'recommend',\n",
       "  'everyone'],\n",
       " ['would', 'u', 'buy', 'this', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First test data point\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b3bbabfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.1968117e-17, 4.0143075e-17, 3.8266378e-17, ..., 4.4379110e-17,\n",
       "       3.8937400e-17, 4.2999598e-17], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the probabilities for the vocab words using the 1st sentence\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b62fc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "81e9fb76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See probability:\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c68b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'further',\n",
       " 'tastier',\n",
       " 'grilled',\n",
       " 'cheaper',\n",
       " 'ina',\n",
       " 'parched',\n",
       " 'capacity',\n",
       " 'open',\n",
       " 'complaint',\n",
       " 'productsthis',\n",
       " 'cabinet',\n",
       " 'good',\n",
       " 'your',\n",
       " 'adds',\n",
       " '44',\n",
       " 'ah',\n",
       " 'mules',\n",
       " 'speed',\n",
       " 'cider',\n",
       " 'pizza',\n",
       " 'late',\n",
       " 'heavy',\n",
       " 'job',\n",
       " 'needed',\n",
       " 'zingyzangy',\n",
       " 'aguas',\n",
       " 'bigger',\n",
       " 'orignalbest',\n",
       " 'nigroni',\n",
       " 'kisses',\n",
       " 'glossy',\n",
       " 'honor',\n",
       " 'corners',\n",
       " 'luccio',\n",
       " 'fresher',\n",
       " 'primer',\n",
       " 'soonand',\n",
       " 'age',\n",
       " 'occasion',\n",
       " 'fear',\n",
       " 'goodie',\n",
       " 'ecstatic',\n",
       " 'hands',\n",
       " 'salad',\n",
       " 'changing',\n",
       " 'sip',\n",
       " 'topped',\n",
       " 'greensburg',\n",
       " 'pinch',\n",
       " 'kansas',\n",
       " 'anytizer',\n",
       " 'aroma',\n",
       " 'handed',\n",
       " 'uses',\n",
       " 'tomato',\n",
       " 'preserver',\n",
       " 'leftovers',\n",
       " 'dad',\n",
       " 'grease',\n",
       " '18and',\n",
       " 'strongbow',\n",
       " 'though',\n",
       " 'said',\n",
       " 'swam',\n",
       " 'littleits',\n",
       " 'jojo',\n",
       " 'sonoran',\n",
       " 'stays',\n",
       " 'maybe',\n",
       " 'operate',\n",
       " 'recomendes',\n",
       " 'elementary',\n",
       " 'chest',\n",
       " 'brutal',\n",
       " 'adult',\n",
       " 'orange',\n",
       " 'coca',\n",
       " 'cherry',\n",
       " 'addition',\n",
       " 'dolls',\n",
       " 'picante',\n",
       " 'staple',\n",
       " 'smoothies',\n",
       " 'carmes',\n",
       " 'reviewer',\n",
       " 'workes',\n",
       " 'assumed',\n",
       " 'addicted',\n",
       " 'brie',\n",
       " 'carnivor',\n",
       " 'lipbalm',\n",
       " 'apart',\n",
       " 'often',\n",
       " 'bottom',\n",
       " 'afresh',\n",
       " 'trials',\n",
       " 'match',\n",
       " 'break',\n",
       " 'patio',\n",
       " 'sea',\n",
       " 'soothing',\n",
       " 'warm',\n",
       " 'retired',\n",
       " 'sippin',\n",
       " 'triangles',\n",
       " 'quality',\n",
       " 'consistent',\n",
       " 'outdoor',\n",
       " 'healing',\n",
       " 'mostly',\n",
       " 'truest',\n",
       " 'organic',\n",
       " 'blistex',\n",
       " 'that',\n",
       " 'ship',\n",
       " '2015',\n",
       " 'physician',\n",
       " 's',\n",
       " 'citrusyness',\n",
       " 'contributions',\n",
       " 'liquefying',\n",
       " '9',\n",
       " 'these',\n",
       " 'brazil',\n",
       " 'wipe',\n",
       " 'competition',\n",
       " 'under',\n",
       " 'durable',\n",
       " 'type',\n",
       " 'px',\n",
       " 'pockets',\n",
       " 'caramel',\n",
       " 'max',\n",
       " 'outs',\n",
       " 'elbows',\n",
       " 'form',\n",
       " 'seasonal',\n",
       " 'life',\n",
       " 'neither',\n",
       " 'travelled',\n",
       " 'coat',\n",
       " 'wether',\n",
       " 'convenience',\n",
       " 'prevent',\n",
       " 'case',\n",
       " 'menage',\n",
       " 'pot',\n",
       " 'enticing',\n",
       " 'wont',\n",
       " 'lingering',\n",
       " 'delights',\n",
       " 'revitalization',\n",
       " 'pocketi',\n",
       " 'laundered',\n",
       " '80salways',\n",
       " 'remotely',\n",
       " 'scemted',\n",
       " 'pharmacy',\n",
       " 'wineas',\n",
       " 'december',\n",
       " 'decided',\n",
       " 'sway',\n",
       " 'even',\n",
       " 'supercenters',\n",
       " 'makeup',\n",
       " 'liqueurs',\n",
       " 'generic',\n",
       " 'melon',\n",
       " 'ticket',\n",
       " 'front',\n",
       " 'reviewers',\n",
       " 'wants',\n",
       " 'pit',\n",
       " 'snappy',\n",
       " 'sturdy',\n",
       " 'smile',\n",
       " 'spout',\n",
       " 'display',\n",
       " 'reach',\n",
       " 'packed',\n",
       " 'heatif',\n",
       " 'ripped',\n",
       " 'topo',\n",
       " 'reputable',\n",
       " 'appear',\n",
       " 'cracking',\n",
       " 'chico',\n",
       " 'beautifully',\n",
       " 'recreational',\n",
       " 'crust',\n",
       " 'lifesaver',\n",
       " 'wonderful',\n",
       " 'surprisingly',\n",
       " 'outrageously',\n",
       " 'show',\n",
       " 'waiting',\n",
       " 'clap',\n",
       " 'tries',\n",
       " 'user',\n",
       " 'benefit',\n",
       " 'availability',\n",
       " 'thank',\n",
       " 'run',\n",
       " 'terrific',\n",
       " 'freeze',\n",
       " '7',\n",
       " 'wouldnt',\n",
       " 'rrrrrough',\n",
       " 'quickie',\n",
       " 'gooey',\n",
       " 'kindergarten',\n",
       " 'whim',\n",
       " 'otherwise',\n",
       " 'setting',\n",
       " 'relieving',\n",
       " 'ms',\n",
       " 'necessarily',\n",
       " 'otherskeep',\n",
       " 'given',\n",
       " 'grateful',\n",
       " 'asian',\n",
       " 'mocktails',\n",
       " 'drain',\n",
       " 'days',\n",
       " 'unwind',\n",
       " 'drypolarwalmart',\n",
       " 'choose',\n",
       " 'old',\n",
       " 'pong',\n",
       " 'barbecue',\n",
       " 'mac',\n",
       " 'notes',\n",
       " 'cuantity',\n",
       " 'whether',\n",
       " 'soften',\n",
       " 'lobby',\n",
       " 'dishes',\n",
       " 'amorphous',\n",
       " 'deal',\n",
       " 'purchasing',\n",
       " 'upset',\n",
       " 'lesser',\n",
       " 'mad',\n",
       " 'neigbors',\n",
       " 'definitely',\n",
       " 'muscadine',\n",
       " 'bonus',\n",
       " 'husband',\n",
       " 'minty',\n",
       " 'yearshaving',\n",
       " 'awesomely',\n",
       " 'surface',\n",
       " 'fight',\n",
       " 'families',\n",
       " 'squeeze',\n",
       " 'yucky',\n",
       " 'enthusiast',\n",
       " 'buddies',\n",
       " 'pro',\n",
       " 'scream',\n",
       " 'find',\n",
       " 'beautiful',\n",
       " 'space',\n",
       " 'buddy',\n",
       " 'alotlove',\n",
       " 'spose',\n",
       " 'mannhattan',\n",
       " 'origional',\n",
       " 'lost',\n",
       " 'inquiry',\n",
       " 'handles',\n",
       " 'usealso',\n",
       " 'competitors',\n",
       " 'talk',\n",
       " 'healed',\n",
       " 'ounce',\n",
       " 'quickly',\n",
       " 'created',\n",
       " 'divorced',\n",
       " 'mind',\n",
       " 'store',\n",
       " 'sweetness',\n",
       " 'freezing',\n",
       " 'suggested',\n",
       " 'heals',\n",
       " 'extra',\n",
       " 'lopez',\n",
       " 'internal',\n",
       " 'fathers',\n",
       " 'gas',\n",
       " 'schweppes',\n",
       " 'size',\n",
       " 'thanks',\n",
       " 'although',\n",
       " 'frequently',\n",
       " 'salve',\n",
       " 'dirt',\n",
       " 'hubby',\n",
       " 'hi',\n",
       " 'amazed',\n",
       " 'putting',\n",
       " 'goodnight',\n",
       " 'stock',\n",
       " 'ststrawberry',\n",
       " 'various',\n",
       " 'unopenedunused',\n",
       " 'pure',\n",
       " 'digger',\n",
       " 'nowi',\n",
       " 'dose',\n",
       " 'wondering',\n",
       " 'solely',\n",
       " 'beloved',\n",
       " 'whiskey',\n",
       " 'reassure',\n",
       " 'aroung',\n",
       " 'aggregate',\n",
       " 'veo',\n",
       " 'nice',\n",
       " 'granddaughters',\n",
       " 'thomas',\n",
       " 'altitude',\n",
       " 'lasts',\n",
       " 'skeptical',\n",
       " 'moisdten',\n",
       " 'icy',\n",
       " 'buying',\n",
       " '15yearold',\n",
       " 'nothings',\n",
       " 'sidewalks',\n",
       " 'zang',\n",
       " 'later',\n",
       " 'want',\n",
       " 'expensive',\n",
       " 'camex',\n",
       " 'needs',\n",
       " 'newbies',\n",
       " 'acidity',\n",
       " 'explode',\n",
       " 'carried',\n",
       " 'unshapable',\n",
       " 'priced',\n",
       " 'theyre',\n",
       " 'sensitive',\n",
       " 'rid',\n",
       " 'contents',\n",
       " 'campari',\n",
       " 'chapped',\n",
       " 'weiners',\n",
       " 'flat',\n",
       " 'switch',\n",
       " 'sprite',\n",
       " 'fortyone',\n",
       " 'provide',\n",
       " 'nightly',\n",
       " 'foot',\n",
       " 'snap',\n",
       " 'acid',\n",
       " 'trois',\n",
       " 'result',\n",
       " 'muffins',\n",
       " 'tang',\n",
       " 'afternoon',\n",
       " 'degenerate',\n",
       " 'hotter',\n",
       " 'balms',\n",
       " 'closer',\n",
       " 'carei',\n",
       " 'specially',\n",
       " 'longlol',\n",
       " 'ie',\n",
       " 'comfort',\n",
       " 'kiss',\n",
       " 'granny',\n",
       " 'budgetfriendly',\n",
       " 'profile',\n",
       " 'sauvignon',\n",
       " 'overpriced',\n",
       " 'bank',\n",
       " 'appealing',\n",
       " 'hit',\n",
       " 'porter',\n",
       " 'occurs',\n",
       " 'design',\n",
       " 'softest',\n",
       " 'exist',\n",
       " 'junkyard',\n",
       " 'through',\n",
       " 'mediumdark',\n",
       " 'refill',\n",
       " 'fransisco',\n",
       " 'usa',\n",
       " 'seen',\n",
       " 'therefore',\n",
       " 'trick',\n",
       " 'incredibly',\n",
       " 'sharing',\n",
       " 'motts',\n",
       " 'holy',\n",
       " 'eating',\n",
       " 'instrument',\n",
       " 'saving',\n",
       " 'wisconsin',\n",
       " 'iraqis',\n",
       " 'learned',\n",
       " 'overbearing',\n",
       " 'cutest',\n",
       " 'esophagus',\n",
       " 'prefer',\n",
       " 'fullbodied',\n",
       " 'sunchapped',\n",
       " 'yearshe',\n",
       " 'multi',\n",
       " 'overnite',\n",
       " 'appetizer',\n",
       " 'anderson',\n",
       " 'gunnison',\n",
       " 'happiest',\n",
       " 'teenage',\n",
       " 'tubes',\n",
       " 'guess',\n",
       " 'per',\n",
       " '831',\n",
       " 'interesting',\n",
       " 'fact',\n",
       " 'j',\n",
       " 'household',\n",
       " 'goto',\n",
       " 'closure',\n",
       " 'unhappy',\n",
       " 'unbeatable',\n",
       " 'regular',\n",
       " 'getting',\n",
       " 'consistency',\n",
       " 'boomer',\n",
       " 'soothers',\n",
       " 'stated',\n",
       " 'winters',\n",
       " 'orowheat',\n",
       " 'hurt',\n",
       " 'calorie',\n",
       " 'distraught',\n",
       " 'heal',\n",
       " 'less',\n",
       " 'always',\n",
       " 'introduced',\n",
       " 'failed',\n",
       " 'rejuvenated',\n",
       " 'hadnt',\n",
       " 'palate',\n",
       " 'fuss',\n",
       " 'soothes',\n",
       " 'grew',\n",
       " 'shrunk',\n",
       " 'writing',\n",
       " 'straightforward',\n",
       " 'slushi',\n",
       " 'bellini',\n",
       " 'corkscrew',\n",
       " 'chose',\n",
       " 'refreshed',\n",
       " 'nearby',\n",
       " 'previously',\n",
       " 'let',\n",
       " 'drug',\n",
       " 'moisturized',\n",
       " 'went',\n",
       " 'sours',\n",
       " 'struggled',\n",
       " 'wears',\n",
       " 'itmy',\n",
       " 'cracked',\n",
       " 'hes',\n",
       " 'strips',\n",
       " 'written',\n",
       " 'rise',\n",
       " 'savior',\n",
       " 'reading',\n",
       " 'breakable',\n",
       " 'l',\n",
       " 'feeling',\n",
       " 'backyard',\n",
       " 'donuts',\n",
       " 'earthy',\n",
       " 'day',\n",
       " 'equilivant',\n",
       " 'week',\n",
       " 'pouring',\n",
       " 'rating',\n",
       " 'matt',\n",
       " 'collins',\n",
       " 'talking',\n",
       " 'cabernets',\n",
       " 'highly',\n",
       " 'themthis',\n",
       " 'fry',\n",
       " 'stationed',\n",
       " 'fragrance',\n",
       " 'locally',\n",
       " 'properly',\n",
       " 'ans',\n",
       " 'need',\n",
       " 'flavorful',\n",
       " 'lime',\n",
       " 'clamato',\n",
       " 'charm',\n",
       " 'fashion',\n",
       " 'couplings',\n",
       " 'moisten',\n",
       " 'application',\n",
       " 'recent',\n",
       " 'greative',\n",
       " 'convert',\n",
       " 'brands',\n",
       " 'movements',\n",
       " 'share',\n",
       " 'discovering',\n",
       " 'attachments',\n",
       " 'passionate',\n",
       " 'usage',\n",
       " 'mattercarmex',\n",
       " 'little',\n",
       " '3212',\n",
       " 'pick',\n",
       " '30jun13',\n",
       " 'terrible',\n",
       " 'citrus',\n",
       " 'maxmum',\n",
       " 'rosemary',\n",
       " 'possible',\n",
       " 'dryer',\n",
       " 'til',\n",
       " 'distributor',\n",
       " 'closeout',\n",
       " '36',\n",
       " 'scallions',\n",
       " 'growing',\n",
       " 'irritation',\n",
       " 'you',\n",
       " 'bright',\n",
       " 'least',\n",
       " 'remained',\n",
       " 'soreness',\n",
       " 'shot',\n",
       " 'chewie',\n",
       " 'fantastic',\n",
       " 'fool',\n",
       " 'blustery',\n",
       " 'celery',\n",
       " 'irvin',\n",
       " 'borrowing',\n",
       " 'membership',\n",
       " 'round1',\n",
       " 'cooking',\n",
       " 'lumps',\n",
       " 'investment',\n",
       " 'roaccutane',\n",
       " 'squeezed',\n",
       " 'skating',\n",
       " 'spoiled',\n",
       " 'excellence',\n",
       " 'becomes',\n",
       " 'searing',\n",
       " 'telling',\n",
       " 'crescent',\n",
       " 'premixed',\n",
       " 'champaign',\n",
       " 'drawer',\n",
       " 'dressing',\n",
       " 'full',\n",
       " '40',\n",
       " 'indentation',\n",
       " 'lipcare',\n",
       " '6',\n",
       " 'aweful',\n",
       " 'hop',\n",
       " 'actually',\n",
       " 'approaching',\n",
       " 'paint',\n",
       " 'discovered',\n",
       " 'cabin',\n",
       " 'rican',\n",
       " 'arid',\n",
       " 'california',\n",
       " 'wehn',\n",
       " 'nicely',\n",
       " 'ia',\n",
       " 'waste',\n",
       " 'residue',\n",
       " 'pros',\n",
       " 'eminently',\n",
       " 'spending',\n",
       " 'eruptions',\n",
       " 'seagrams',\n",
       " 'uknowlingly',\n",
       " 'washed',\n",
       " 'dink',\n",
       " 'inexpensive',\n",
       " 'walking',\n",
       " 'upon',\n",
       " 'imbibing',\n",
       " 'topnotch',\n",
       " 'cheese',\n",
       " 'any',\n",
       " 'enjoy',\n",
       " 'courtesans',\n",
       " 'fill',\n",
       " 'thick',\n",
       " 'beats',\n",
       " 'keeping',\n",
       " 'flavor',\n",
       " 'applications',\n",
       " 'caneven',\n",
       " 'oil',\n",
       " 'reliever',\n",
       " 'purseand',\n",
       " 'fabulousness',\n",
       " 'puzzle',\n",
       " 'anything',\n",
       " 'stuck',\n",
       " 'drink',\n",
       " 'cures',\n",
       " 'sickness',\n",
       " 'products',\n",
       " 'workin',\n",
       " 'listed',\n",
       " 'supplements',\n",
       " 'wrong',\n",
       " 'panic',\n",
       " 'liops',\n",
       " 'extending',\n",
       " 'hardly',\n",
       " 'trash',\n",
       " 'present',\n",
       " 'icys',\n",
       " 'diabetic',\n",
       " 'zingzang',\n",
       " 'gz',\n",
       " 'authentic',\n",
       " 'mess',\n",
       " 'yep',\n",
       " 'bahamas',\n",
       " 'rums',\n",
       " 'chronic',\n",
       " 'percent',\n",
       " 'manner',\n",
       " 'lose',\n",
       " 'birthday',\n",
       " 'blooding',\n",
       " 'tell',\n",
       " 'heay',\n",
       " 'thinking',\n",
       " 'prefect',\n",
       " 'smoothness',\n",
       " 'goya',\n",
       " 'ur',\n",
       " 'jelly',\n",
       " 'sauce',\n",
       " 'thickalmost',\n",
       " 'midday',\n",
       " 'cheeks',\n",
       " 'encounter',\n",
       " 'pleasure',\n",
       " 'humid',\n",
       " 'complaints',\n",
       " 'enough',\n",
       " 'caffine',\n",
       " 'constantly',\n",
       " 'branded',\n",
       " 'pepper',\n",
       " 'commented',\n",
       " 'than',\n",
       " 'ditch',\n",
       " 'twisted',\n",
       " 'constant',\n",
       " 'protect',\n",
       " 'normally',\n",
       " 'nothing',\n",
       " 'breast',\n",
       " 'heart',\n",
       " 'yearly',\n",
       " 'if',\n",
       " 'exaggerating',\n",
       " 'kudos',\n",
       " 'machines',\n",
       " 'shiny',\n",
       " 'bomb',\n",
       " 'sore',\n",
       " 'sponsor',\n",
       " 'glad',\n",
       " 'electronic',\n",
       " 'michelada',\n",
       " 'unscrew',\n",
       " 'v8being',\n",
       " 'tp',\n",
       " 'screwed',\n",
       " 'nostalgia',\n",
       " 'ones',\n",
       " 'scared',\n",
       " 'needing',\n",
       " 'extreme',\n",
       " 'carmexwho',\n",
       " 'daiquiris',\n",
       " 'useful',\n",
       " 'ands',\n",
       " 'manageable',\n",
       " 'deck',\n",
       " 'will',\n",
       " 'trywow',\n",
       " 'relieve',\n",
       " 'pay',\n",
       " 'knowledge',\n",
       " 'cancer',\n",
       " 'cocteaus',\n",
       " 'protectors',\n",
       " 'ensure',\n",
       " 'uncharge',\n",
       " 'exchange',\n",
       " 'oct',\n",
       " 'proudly',\n",
       " 'marys',\n",
       " 'sooner',\n",
       " 'dreaded',\n",
       " 'mary',\n",
       " 'drove',\n",
       " 'world',\n",
       " 'chill',\n",
       " 'moisture',\n",
       " 'prompt',\n",
       " 'northeastern',\n",
       " 'wyngz',\n",
       " 'veterans',\n",
       " 'admit',\n",
       " 'pause',\n",
       " 'replacement',\n",
       " 'boat',\n",
       " 'protecting',\n",
       " 'leakage',\n",
       " 'tradition',\n",
       " 'guy',\n",
       " 'zingy',\n",
       " 'cna',\n",
       " 'everywhere',\n",
       " 'syrups',\n",
       " 'seemed',\n",
       " 'sipping',\n",
       " 'pleased',\n",
       " 'god',\n",
       " 'measure',\n",
       " 'eat',\n",
       " 'woman',\n",
       " 'crown',\n",
       " 'pricey',\n",
       " 'when',\n",
       " 'sisters',\n",
       " 'manhood',\n",
       " 'brush',\n",
       " 'losing',\n",
       " 'blanc',\n",
       " 'style',\n",
       " 'impressing',\n",
       " 'anywherei',\n",
       " 'finger',\n",
       " 'wide',\n",
       " 'therapy',\n",
       " 'powders',\n",
       " 'meat',\n",
       " 'compared',\n",
       " 'anywhere',\n",
       " '80s',\n",
       " 'why',\n",
       " 'tried',\n",
       " 'cinnamon',\n",
       " 'sizei',\n",
       " 'station',\n",
       " 'offbrands',\n",
       " 'gassy',\n",
       " 'delighted',\n",
       " 'oldie',\n",
       " '26',\n",
       " 'strong',\n",
       " 'visa',\n",
       " 'choice',\n",
       " 'changes',\n",
       " 'chance',\n",
       " 'caution',\n",
       " 'hose',\n",
       " 'totally',\n",
       " 'greaprice',\n",
       " 'paying',\n",
       " 'plain',\n",
       " 'includes',\n",
       " 'okay',\n",
       " 'postop',\n",
       " 'trumpet',\n",
       " 'current',\n",
       " 'waxing',\n",
       " 'prone',\n",
       " 'away',\n",
       " 'powerful',\n",
       " 'habit',\n",
       " 'industry',\n",
       " 'upscale',\n",
       " 'silky',\n",
       " 'death',\n",
       " 'round',\n",
       " 'sits',\n",
       " 'sooth',\n",
       " 'build',\n",
       " 'improve',\n",
       " 'move',\n",
       " 'safely',\n",
       " 'swears',\n",
       " 'jeans',\n",
       " 'generation',\n",
       " 'might',\n",
       " 'caused',\n",
       " 'cottage',\n",
       " 'supermarket',\n",
       " 'shyed',\n",
       " 'alternative',\n",
       " 'country',\n",
       " 'crumbs',\n",
       " 'something',\n",
       " 'future',\n",
       " 'gets',\n",
       " 'olives',\n",
       " 'grapes',\n",
       " 'word',\n",
       " 'blistered',\n",
       " 'miss',\n",
       " 'homemade',\n",
       " 'derived',\n",
       " 'carmexafter',\n",
       " 'shopping',\n",
       " 'freein',\n",
       " 'tickled',\n",
       " 'exotic',\n",
       " 'sure',\n",
       " 'smell',\n",
       " 'except',\n",
       " 'knows',\n",
       " 'boys',\n",
       " 'player',\n",
       " 'painful',\n",
       " 'rim',\n",
       " 'walmart',\n",
       " 'porch',\n",
       " 'town',\n",
       " 'tyson',\n",
       " 'franks',\n",
       " 'inhale',\n",
       " 'kissable',\n",
       " 'bubbles',\n",
       " 'fits',\n",
       " 'track',\n",
       " 'coworker',\n",
       " 'excited',\n",
       " 'addictive',\n",
       " 'state',\n",
       " 'cola',\n",
       " 'abilities',\n",
       " 'office',\n",
       " 'wings',\n",
       " 'bagpurse',\n",
       " 'become',\n",
       " 'lipsticks',\n",
       " 'oasis',\n",
       " 'coated',\n",
       " 'shoot',\n",
       " 'blisters',\n",
       " 'accept',\n",
       " 'toasting',\n",
       " 'busy',\n",
       " 'minerality',\n",
       " 'screwdrivers',\n",
       " 'riding',\n",
       " 'splurge',\n",
       " 'as',\n",
       " 'unroll',\n",
       " 'collected',\n",
       " 'delivery',\n",
       " 'second',\n",
       " 'areai',\n",
       " 'celsius',\n",
       " 'blackberry',\n",
       " 'chilli',\n",
       " 'washington',\n",
       " 'minute',\n",
       " 'children',\n",
       " 'hits',\n",
       " 'sooths',\n",
       " 'contaminated',\n",
       " 'droplets',\n",
       " 'starting',\n",
       " 'poured',\n",
       " 'fifteen',\n",
       " 'bind',\n",
       " 'number',\n",
       " 'oxen',\n",
       " 'washes',\n",
       " 'draw',\n",
       " 'resort',\n",
       " 'winter',\n",
       " 'chin',\n",
       " 'cayman',\n",
       " 'sons',\n",
       " 'restorative',\n",
       " 'reasonsit',\n",
       " 'wineblend',\n",
       " 'trademark',\n",
       " 'youve',\n",
       " 'recipe',\n",
       " '2013',\n",
       " 'lid',\n",
       " 'pushed',\n",
       " 'nieces',\n",
       " 'treatment',\n",
       " 'groceries',\n",
       " 'stand',\n",
       " 'distinctive',\n",
       " 'feel',\n",
       " 'definately',\n",
       " 'damaged',\n",
       " 'sweeteners',\n",
       " 'happen',\n",
       " 'rusted',\n",
       " '3rd',\n",
       " 'moms',\n",
       " 'anyones',\n",
       " 'write',\n",
       " 'fructose',\n",
       " 'shop',\n",
       " 'nozzle',\n",
       " '1997',\n",
       " 'xwith',\n",
       " 'connection',\n",
       " 'south',\n",
       " 'cressants',\n",
       " 'handy',\n",
       " 'disappointed',\n",
       " 'spreading',\n",
       " 'sauced',\n",
       " 'irregular',\n",
       " 'cheeper',\n",
       " 'calories',\n",
       " 'service',\n",
       " 'pry',\n",
       " 'affect',\n",
       " 'pkg',\n",
       " 'faced',\n",
       " 'traditions',\n",
       " 'reno',\n",
       " 'compete',\n",
       " 'traveled',\n",
       " 'chardonnay',\n",
       " 'freezer',\n",
       " 'zinfindel',\n",
       " 'approved',\n",
       " 'chambord',\n",
       " 'roll',\n",
       " 'michigan',\n",
       " 'keeps',\n",
       " 'drys',\n",
       " 'crannies',\n",
       " 'avoid',\n",
       " 'diaper',\n",
       " 'washing',\n",
       " 'wrinkles',\n",
       " 'skinny',\n",
       " 'works',\n",
       " 'grape',\n",
       " 'mans',\n",
       " 'spring',\n",
       " 'marqueritas',\n",
       " 'handing',\n",
       " 'vince',\n",
       " 'bakes',\n",
       " 'officially',\n",
       " 'finding',\n",
       " 'tingling',\n",
       " 'rolling',\n",
       " 'ago',\n",
       " 'louisiana',\n",
       " 'powering',\n",
       " 'toget',\n",
       " 'pharmacist',\n",
       " 'undamaged',\n",
       " 'moscow',\n",
       " 'replaced',\n",
       " 'sugars',\n",
       " 'trying',\n",
       " 'dropped',\n",
       " 'divine',\n",
       " 'account',\n",
       " 'stable',\n",
       " 'chapping',\n",
       " 'hs',\n",
       " 'diy',\n",
       " 'ways',\n",
       " ...}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we can make our own questions using the vocabulary we have\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3303b523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4506"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "09874fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"would u buy this ?\"\n",
    "\n",
    "some_input = \"tickled my nose\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "13cf2600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def get_new_input():\n",
    "\n",
    "    idx = 0\n",
    "    new_input = \"\"\n",
    "\n",
    "    while idx < 11:\n",
    "        new_input = new_input + list(vocab)[randint(0, len(vocab))] + \" \"\n",
    "        idx += 1\n",
    "\n",
    "    return new_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8d7c4ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selection():\n",
    "    choose = ['yes', 'no']\n",
    "\n",
    "    selection = randint(0,1)\n",
    "    \n",
    "    return choose[selection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45033bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_of_input(some_input=None):\n",
    "    #Put the data in the same format as before\n",
    "    \n",
    "    if some_input == None:\n",
    "        some_input = get_new_input()\n",
    "    \n",
    "    print(some_input)    \n",
    "    \n",
    "    selection = get_selection()\n",
    "    \n",
    "    my_data = [(some_input.split(), my_question.split(), selection)]\n",
    "    \n",
    "    #Vectorize this data\n",
    "    my_input, my_ques, my_ans = vectorize_stories(my_data)\n",
    "\n",
    "    #Make the prediction\n",
    "    pred_results = model.predict(([my_input, my_ques]))\n",
    "    \n",
    "    val_max = np.argmax(pred_results[0])\n",
    "    \n",
    "    #Correct prediction!\n",
    "    for key,val in tokenizer.word_index.items():\n",
    "        if val == val_max:\n",
    "            k = key\n",
    "    print('answer : ', k)\n",
    "    \n",
    "    #Confidence\n",
    "    print('confidence : ', pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "763de975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brand leak lightweight flint cocktails greatthis creamy trouble 15yearold opinion zang \n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b31a5731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c mixes stayed exactly straight drop brunch seamless salt iraqis bulky \n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e7061f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medicated chapstick seemed edgewood compared impending tell overnite chemicals roscato lovely \n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "27ac0e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vary marys worse golf few guy liqueurs melts carmex whiskey excellenti \n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4c03e35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reasonably temps almost diabetes fallen 450 protective entergetic isnt porcelain fumes \n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "170aa8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really liked this wine i will buy it\n",
      "answer :  yes\n",
      "confidence :  1.0\n"
     ]
    }
   ],
   "source": [
    "get_pred_of_input('i really liked this wine i will buy it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "87a25478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'again' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "379c4bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i really liked this wine i will buy it again\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'again'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ry/gtypcvm50js8j8wlbz5z7h6m0000gn/T/ipykernel_35261/2863327328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_pred_of_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i really liked this wine i will buy it again'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/ry/gtypcvm50js8j8wlbz5z7h6m0000gn/T/ipykernel_35261/1892426920.py\u001b[0m in \u001b[0;36mget_pred_of_input\u001b[0;34m(some_input)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#Vectorize this data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_ques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorize_stories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#Make the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ry/gtypcvm50js8j8wlbz5z7h6m0000gn/T/ipykernel_35261/650052148.py\u001b[0m in \u001b[0;36mvectorize_stories\u001b[0;34m(data, word_index, max_review_len, max_question_len)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Getting indexes for each word in the story\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#Getting indexes for each word in the story\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mxq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ry/gtypcvm50js8j8wlbz5z7h6m0000gn/T/ipykernel_35261/650052148.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Getting indexes for each word in the story\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#Getting indexes for each word in the story\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mxq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'again'"
     ]
    }
   ],
   "source": [
    "get_pred_of_input('i really liked this wine i will buy it again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0e8217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b95e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032b510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754d9fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
