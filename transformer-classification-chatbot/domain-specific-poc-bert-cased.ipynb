{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3954ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# pretrained_BERT and botswine\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "from transformers import BertConfig\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "#from tokenizers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e6f18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3460: DtypeWarning: Columns (3,27) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../master-thesis/data/dataset1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a8137de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Note', 'varietal_name']]\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b599a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd22b007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Note.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19745e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130197, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb7290bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(\"Note\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "945cafe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59211, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1808dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset dataset1 just for the top contenders\n",
    "df = df[(df['varietal_name'] == 'Cabernet Sauvignon') \\\n",
    "                    |(df['varietal_name'] == 'Chardonnay') \\\n",
    "                    |(df['varietal_name'] == 'Côte de Beaune White')\\\n",
    "                    |(df['varietal_name'] == 'Côte de Nuits Red')\\\n",
    "                    |(df['varietal_name'] == 'Riesling')\\\n",
    "                    |(df['varietal_name'] == 'Pomerol')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ce1b4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14167, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b51b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.sample(frac = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7923b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[~df.isin(train)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05dbf6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square True\n",
    "test.shape[0]+train.shape[0]==df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ea86c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['index'] = test['index'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba3bff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vn_unqs = train.varietal_name.unique()\n",
    "train_vn_unqs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42f8e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vn_unqs = test.varietal_name.unique()\n",
    "test_vn_unqs.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "707c4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={\n",
    "    \"index\": \"id\",\n",
    "    \"Note\": \"text\",\n",
    "    \"varietal_name\": \"label\"\n",
    "}, inplace=True)\n",
    "\n",
    "test.rename(columns={\n",
    "    \"index\": \"id\",\n",
    "    \"Note\": \"text\",\n",
    "    \"varietal_name\": \"label\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90978ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123022</th>\n",
       "      <td>123022</td>\n",
       "      <td>シャルドネ\\nそこまでは。</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123403</th>\n",
       "      <td>123403</td>\n",
       "      <td>butter vanilla oak melon minerals butterscotch</td>\n",
       "      <td>Chardonnay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128918</th>\n",
       "      <td>128918</td>\n",
       "      <td>Goed als je veel dorst hebt.</td>\n",
       "      <td>Côte de Beaune White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121043</th>\n",
       "      <td>121043</td>\n",
       "      <td>Не кислое, слегка минеральное, мягкое, приятное</td>\n",
       "      <td>Côte de Beaune White</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111811</th>\n",
       "      <td>111811</td>\n",
       "      <td>Perfection!\\n</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              text  \\\n",
       "123022  123022                                     シャルドネ\\nそこまでは。   \n",
       "123403  123403    butter vanilla oak melon minerals butterscotch   \n",
       "128918  128918                      Goed als je veel dorst hebt.   \n",
       "121043  121043  Не кислое, слегка минеральное, мягкое, приятное    \n",
       "111811  111811                                     Perfection!\\n   \n",
       "\n",
       "                       label  \n",
       "123022            Chardonnay  \n",
       "123403            Chardonnay  \n",
       "128918  Côte de Beaune White  \n",
       "121043  Côte de Beaune White  \n",
       "111811    Cabernet Sauvignon  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae11f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train)\n",
    "test_dataset = datasets.Dataset.from_pandas(test)\n",
    "dataset = datasets.DatasetDict({\"train\":train_dataset,\n",
    "                                        \"test\":test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2374d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10625/10625 [00:00<00:00, 22711.49it/s]\n"
     ]
    }
   ],
   "source": [
    "text_data = []\n",
    "file_count = 0\n",
    "\n",
    "for sample in tqdm(dataset['train']):\n",
    "    sample = sample['text'].replace('\\n', '')\n",
    "    text_data.append(sample)\n",
    "    if len(text_data) == 10_000:\n",
    "        # once we git the 10K mark, save to file\n",
    "        with open(f'text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "            fp.write('\\n'.join(text_data))\n",
    "        text_data = []\n",
    "        file_count += 1\n",
    "# after saving in 10K chunks, we will have ~2082 leftover samples, we save those now too\n",
    "with open(f'text_{file_count}.txt', 'w', encoding='utf-8') as fp:\n",
    "    fp.write('\\n'.join(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3042d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "paths = [str(x) for x in Path('').glob('*.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2ad8d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "792099bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.train(files=paths[:5], vocab_size=30_522, min_frequency=2,\n",
    "                special_tokens=['<s>', '<pad>', '</s>', '<unk>', '<mask>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8906cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/vocab.json', 'models/merges.txt']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9706fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the tokenizer using the tokenizer we initialized and saved to file\n",
    "#tokenizer = RobertaTokenizer.from_pretrained('bert-base-cased', max_len=512)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', max_len=512)\n",
    "#model = TFBertModel.from_pretrained(\"bert-base-cased\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e37a7f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our tokenizer on a simple sentence\n",
    "tokens = tokenizer('id like a dry red wine with my veal salad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7304b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_0.txt', 'r', encoding='utf-8') as fp:\n",
    "    lines = fp.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a6f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = tokenizer(lines, max_length=512, padding='max_length', truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6af6cac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2efbe7b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da40e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(batch.input_ids)\n",
    "mask = torch.tensor(batch.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de5c5b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copy of labels tensor, this will be input_ids\n",
    "input_ids = labels.detach().clone()\n",
    "# create random array of floats with equal dims to input_ids\n",
    "rand = torch.rand(input_ids.shape)\n",
    "# mask random 15% where token is not 0 [PAD], 1 [CLS], or 2 [SEP]\n",
    "mask_arr = (rand < .15) * (input_ids != 0) * (input_ids != 1) * (input_ids != 2)\n",
    "# loop through each row in input_ids tensor (cannot do in parallel)\n",
    "for i in range(input_ids.shape[0]):\n",
    "    # get indices of mask positions from mask array\n",
    "    selection = torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    # mask input_ids\n",
    "    input_ids[i, selection] = 3  # our custom [MASK] token == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "230e0769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10013, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53085308",
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = {'input_ids': input_ids, 'attention_mask': mask, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72a8af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        # store encodings internally\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        # return the number of samples\n",
    "        return self.encodings['input_ids'].shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # return dictionary of input_ids, attention_mask, and labels for index i\n",
    "        return {key: tensor[i] for key, tensor in self.encodings.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bce73f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5988cbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d73e4ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    vocab_size=tokenizer.vocab_size,  # we align this to the tokenizer vocab_size\n",
    "    max_position_embeddings=514,\n",
    "    hidden_size=768,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2764bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef2bf2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=28996, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# and move our model over to the selected device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "716d450e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# activate training mode\n",
    "model.train()\n",
    "\n",
    "# initialize optimizer\n",
    "optim = AdamW(model.parameters(), lr=1e-5)\n",
    "#optim = AdamW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f9f72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   3%|██▊                                                                                                | 18/626 [19:34<11:53:54, 70.45s/it, loss=10.2]"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Epoch {epoch}')\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bce546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('models/winedomainspecificbertpoc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58b017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141cac96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae4067b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-experiments",
   "language": "python",
   "name": "bert-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
